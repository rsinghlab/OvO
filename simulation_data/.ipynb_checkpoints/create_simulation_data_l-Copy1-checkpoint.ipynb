{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db22181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7be4b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = list(range(20)))\n",
    "for i in range(1000):\n",
    "    l = np.random.dirichlet(np.ones(20),size=1)[0]\n",
    "    l2 = np.random.uniform(0,0.15,20)\n",
    "    std1 = l.std()\n",
    "    std2 = l2.std()\n",
    "    arr = []\n",
    "    arr2 = []\n",
    "    for j in range(len(l2)):\n",
    "        arr.append(np.random.uniform(l[j] - std1 ,l[j]  + std1,20))\n",
    "        arr2.append(np.random.uniform(l2[j] - std2 ,l2[j]  + std2,20))\n",
    "    \n",
    "    df_temp = pd.DataFrame([arr, arr2])\n",
    "    df = df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d4f8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ab2d199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.1425291059511972, 0.1427490584012465, 0.064...</td>\n",
       "      <td>[0.08610056879213501, 0.12178451887607245, 0.1...</td>\n",
       "      <td>[0.005027882676477292, 0.014423904255524037, -...</td>\n",
       "      <td>[0.11386409884702459, 0.03248970179094752, 0.0...</td>\n",
       "      <td>[-0.036309577127568146, -0.02121906611363441, ...</td>\n",
       "      <td>[0.044602493983996155, 0.05995862866779936, 0....</td>\n",
       "      <td>[0.09334196057819108, 0.042253172799132765, 0....</td>\n",
       "      <td>[-0.010183451277868202, 0.01245298332715052, 0...</td>\n",
       "      <td>[-0.02725731639487562, 0.019496893147104413, -...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.004370444473687236, 0.0012803431762743872,...</td>\n",
       "      <td>[-0.0008438477891762886, -0.016462048702332692...</td>\n",
       "      <td>[0.14279538847118695, 0.1504154664021815, 0.09...</td>\n",
       "      <td>[0.11294591510584956, 0.10190435072707164, 0.1...</td>\n",
       "      <td>[0.04069369212513115, 0.05192730568117687, 0.0...</td>\n",
       "      <td>[0.17146587360301205, 0.1516378956918845, 0.13...</td>\n",
       "      <td>[0.052388034258788685, 0.007397828903799072, 0...</td>\n",
       "      <td>[0.05133338291285723, -0.01201405857699753, 0....</td>\n",
       "      <td>[0.041525543436852545, -0.011103649970985126, ...</td>\n",
       "      <td>[0.04349728067940602, 0.01602649069027814, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.09026107284806115, 0.06150244142972182, 0.0...</td>\n",
       "      <td>[0.04538937670938503, 0.05308249335581676, 0.0...</td>\n",
       "      <td>[0.11987957003036875, 0.1515483946939712, 0.11...</td>\n",
       "      <td>[0.09121350961371177, 0.0659840492358891, 0.11...</td>\n",
       "      <td>[0.16635251289056696, 0.1343653560776765, 0.10...</td>\n",
       "      <td>[0.13503600246340933, 0.15183458098893846, 0.1...</td>\n",
       "      <td>[0.024411648392230555, 0.09079993641305957, 0....</td>\n",
       "      <td>[0.07346185121773145, 0.099639496104335, 0.090...</td>\n",
       "      <td>[0.010426223384971362, 0.03856450592151311, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.18139046124944358, 0.12763791954767872, 0.1...</td>\n",
       "      <td>[0.040863743652190226, 0.07501025908085429, 0....</td>\n",
       "      <td>[0.10976158723796357, 0.10558312438223087, 0.1...</td>\n",
       "      <td>[0.0377938173925821, 0.04197967886427428, 0.04...</td>\n",
       "      <td>[0.06481156522533488, 0.0849914691623969, 0.05...</td>\n",
       "      <td>[0.08622352814126706, 0.08594728731593484, 0.1...</td>\n",
       "      <td>[0.08705411374511021, 0.15051393652211248, 0.1...</td>\n",
       "      <td>[0.14209529176817465, 0.15320980344275378, 0.1...</td>\n",
       "      <td>[0.1358522869401525, 0.1233307187259513, 0.076...</td>\n",
       "      <td>[0.11515842269915107, 0.08387805282589375, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.10379803421266834, 0.03487742674994996, 0.0...</td>\n",
       "      <td>[0.05241632620285876, 0.009666815823901349, -0...</td>\n",
       "      <td>[0.03426888074694801, 0.05330306670983995, 0.0...</td>\n",
       "      <td>[0.0448579504495472, 0.012665274218030632, -0....</td>\n",
       "      <td>[0.1295437098904198, 0.06001705681827446, 0.08...</td>\n",
       "      <td>[0.058584378280174626, 0.044242129859667106, 0...</td>\n",
       "      <td>[0.03571457501426369, 0.0054818679344868955, 0...</td>\n",
       "      <td>[-0.01681491854523136, -0.021577889193778538, ...</td>\n",
       "      <td>[0.013671440346787841, 0.06960063313824948, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.038046655138093875, -0.020977835432432496,...</td>\n",
       "      <td>[-0.01746827751205943, 0.04956841253120914, -0...</td>\n",
       "      <td>[-0.02114032236145766, 0.06490861359079454, 0....</td>\n",
       "      <td>[0.24609106121795798, 0.18074583987838458, 0.1...</td>\n",
       "      <td>[0.026843031984688907, 0.05715441124286436, 0....</td>\n",
       "      <td>[0.07468277961919811, 0.06741454661969365, 0.0...</td>\n",
       "      <td>[0.06148104835203988, 0.07690584646783945, 0.0...</td>\n",
       "      <td>[0.0038222565040456962, 0.05009315363189586, 0...</td>\n",
       "      <td>[0.05951629244044407, 0.016282464377705187, 0....</td>\n",
       "      <td>[0.049718757651829544, 0.03751878346120866, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.06946228364788944, 0.09693821656515499, 0.1...</td>\n",
       "      <td>[0.09832563902423447, 0.07066609313822994, 0.0...</td>\n",
       "      <td>[0.045218165297132434, 0.0375920805571551, 0.0...</td>\n",
       "      <td>[0.05997075400652483, 0.0025540526755087126, 0...</td>\n",
       "      <td>[0.10346367040198412, 0.07852072303922047, 0.1...</td>\n",
       "      <td>[0.11391956226463648, 0.16234800047703712, 0.1...</td>\n",
       "      <td>[0.09807316440294812, 0.0870695551620023, 0.04...</td>\n",
       "      <td>[0.03834438717966448, -0.006503626931474042, 0...</td>\n",
       "      <td>[0.02718891249089698, 0.06585193318954866, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.11494618854379515, 0.11719455190465707, 0.0...</td>\n",
       "      <td>[0.08628512585459558, 0.059011228725845334, 0....</td>\n",
       "      <td>[-0.012603319937051407, 0.030363603721201397, ...</td>\n",
       "      <td>[0.026195223606124553, 0.06392444261333008, 0....</td>\n",
       "      <td>[0.023335795838676107, -0.002135853540557949, ...</td>\n",
       "      <td>[0.11010470502185954, 0.10939339996580533, 0.1...</td>\n",
       "      <td>[0.12337461495884046, 0.06555766431303268, 0.0...</td>\n",
       "      <td>[0.11930642522793342, 0.10306962102384157, 0.1...</td>\n",
       "      <td>[0.1203724099958524, 0.1362173487217062, 0.141...</td>\n",
       "      <td>[0.029218288979118448, 0.0009392166636504121, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.07317925682411716, 0.04308888324317473, 0.0...</td>\n",
       "      <td>[0.03933238723806587, 0.035817914239608006, 0....</td>\n",
       "      <td>[0.018353812762015302, 0.021751701170880357, 0...</td>\n",
       "      <td>[0.06205677339596287, 0.10661882526596095, 0.0...</td>\n",
       "      <td>[0.11719792183880774, 0.0824210294777011, 0.11...</td>\n",
       "      <td>[0.04484371412272097, 0.056542809789619834, 0....</td>\n",
       "      <td>[0.03280576845666359, -0.02185083727878013, 0....</td>\n",
       "      <td>[0.047304235633775026, 0.032387129456268614, 0...</td>\n",
       "      <td>[0.02474545172467214, 0.04227512884907455, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.08763814000919284, 0.12003810135952675, 0.1...</td>\n",
       "      <td>[0.02800378208319385, 0.001342310891320062, 0....</td>\n",
       "      <td>[0.04035642014640546, 0.08219495878636537, 0.0...</td>\n",
       "      <td>[-0.0025751516308632275, -0.03355490706132226,...</td>\n",
       "      <td>[0.09145028671125861, 0.12359534550040212, 0.1...</td>\n",
       "      <td>[0.03424462582179037, 0.02599719607520608, 0.0...</td>\n",
       "      <td>[0.07316866563213471, 0.03120491294503651, 0.0...</td>\n",
       "      <td>[0.07245593076891103, 0.07517045955627918, 0.0...</td>\n",
       "      <td>[0.17693769273899201, 0.14398669290619506, 0.1...</td>\n",
       "      <td>[0.030750248484464053, 0.04810908861741681, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.12493658141290107, 0.12689697375001657, 0.1...</td>\n",
       "      <td>[0.059188699293574, 0.08272885373777021, 0.106...</td>\n",
       "      <td>[0.034189102695024384, 0.036194019765602235, 0...</td>\n",
       "      <td>[0.062271430510493574, 0.06323048871686557, 0....</td>\n",
       "      <td>[0.08840770765352546, 0.07532380744981028, 0.0...</td>\n",
       "      <td>[0.045926471886868575, 0.0534375811830377, 0.0...</td>\n",
       "      <td>[0.06296620305514036, 0.022889441448729415, 0....</td>\n",
       "      <td>[0.05035404703234739, 0.029742635370106633, 0....</td>\n",
       "      <td>[0.0812417860374218, 0.061490101207917355, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0788604205383896, 0.12142890841649173, 0.11...</td>\n",
       "      <td>[0.008275963496682628, 0.02585088367749012, 0....</td>\n",
       "      <td>[0.05995074681912563, 0.07491643506597612, 0.0...</td>\n",
       "      <td>[0.07526386553249556, 0.04114470524258412, 0.0...</td>\n",
       "      <td>[0.07433706446941468, 0.052957708636133555, 0....</td>\n",
       "      <td>[0.09115784757681866, 0.1004452551735828, 0.04...</td>\n",
       "      <td>[0.07452955252660931, 0.09078906782969468, 0.0...</td>\n",
       "      <td>[0.039728744938438657, 0.021819043882844422, 0...</td>\n",
       "      <td>[0.04494585172002373, 0.05542943762681147, 0.0...</td>\n",
       "      <td>[0.11593676641571117, 0.09713573312622881, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.04860533866349404, 0.006076427807596846, 0....</td>\n",
       "      <td>[0.0375482338236825, -0.004796497136600264, 0....</td>\n",
       "      <td>[-0.021410043433903788, 0.007444390920218594, ...</td>\n",
       "      <td>[0.026928433517584338, 0.07413738669426406, 0....</td>\n",
       "      <td>[0.08604201091054361, 0.09036525676510573, 0.0...</td>\n",
       "      <td>[0.02353306081653777, 0.017643947845763355, 0....</td>\n",
       "      <td>[0.17543667477893674, 0.17237662975654225, 0.1...</td>\n",
       "      <td>[0.03352560451795513, 0.06512977191882435, 0.0...</td>\n",
       "      <td>[0.010429266546777491, 0.03958361633422225, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0978964493268017, 0.08159608608684248, 0.04...</td>\n",
       "      <td>[0.032987301004670504, 0.06103057005537256, 0....</td>\n",
       "      <td>[0.047682049131733545, 0.03421068387204099, -0...</td>\n",
       "      <td>[0.056831823089551696, 0.11313197152646642, 0....</td>\n",
       "      <td>[0.047918206642892085, 0.009353498377265432, 0...</td>\n",
       "      <td>[0.03333462589460928, 0.046663450804679596, -0...</td>\n",
       "      <td>[0.16285263053567656, 0.1999079442196383, 0.17...</td>\n",
       "      <td>[0.0022758915635143484, 0.016323449067340262, ...</td>\n",
       "      <td>[0.06500477451488632, 0.050653981466706396, 0....</td>\n",
       "      <td>[0.040542859090054485, 0.014000753423258537, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.15497855978786215, 0.14595640349256533, 0.1...</td>\n",
       "      <td>[0.15015638649004998, 0.12473079907892935, 0.1...</td>\n",
       "      <td>[0.07338209574325391, 0.09258332717793114, 0.1...</td>\n",
       "      <td>[-0.006147194705856647, 0.02095478271814918, -...</td>\n",
       "      <td>[0.11453821225420323, 0.14541325162488494, 0.1...</td>\n",
       "      <td>[0.07530986578459772, 0.05484522055153167, 0.0...</td>\n",
       "      <td>[0.11361606807018054, 0.10088559727546198, 0.0...</td>\n",
       "      <td>[0.06184192787995971, 0.07564282962688629, 0.1...</td>\n",
       "      <td>[0.05054253483519612, 0.055045897972012606, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.125990966843816, 0.14429319597512696, 0.111...</td>\n",
       "      <td>[0.11855254163266152, 0.18141762838474443, 0.1...</td>\n",
       "      <td>[0.06275210604135785, 0.0342744585985594, 0.08...</td>\n",
       "      <td>[0.03905791221125657, 0.07366135773538292, 0.0...</td>\n",
       "      <td>[0.06080626260930224, 0.07671166299132559, 0.1...</td>\n",
       "      <td>[0.10595094121876673, 0.09895953288301954, 0.1...</td>\n",
       "      <td>[0.14283868481305545, 0.13659785117346201, 0.0...</td>\n",
       "      <td>[0.0654320176103439, 0.03301065580908678, 0.06...</td>\n",
       "      <td>[0.11855149179931594, 0.07580638241162788, 0.1...</td>\n",
       "      <td>[0.09749568264469863, 0.12940440408733556, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.01519477520271758, 0.003058235823519981, 0....</td>\n",
       "      <td>[0.2116208103744061, 0.19621462118841362, 0.18...</td>\n",
       "      <td>[0.097123607930022, 0.015435691085134335, 0.08...</td>\n",
       "      <td>[0.022273018490969777, 0.11487904236583324, 0....</td>\n",
       "      <td>[0.0425772654754845, 0.03332029083938193, 0.03...</td>\n",
       "      <td>[0.011614932229236978, -0.017606038827710373, ...</td>\n",
       "      <td>[0.0721453210167938, 0.02765562474166327, 0.02...</td>\n",
       "      <td>[0.03467822376888466, 0.11483958752992302, 0.0...</td>\n",
       "      <td>[0.10552556111479028, 0.040904221060112635, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.00390743867216637, -0.018137976173359723, -...</td>\n",
       "      <td>[-0.012064404194704226, 0.003779045510148467, ...</td>\n",
       "      <td>[0.08774569876570498, 0.00046272257541874005, ...</td>\n",
       "      <td>[0.08805965871243143, 0.021387356567461747, 0....</td>\n",
       "      <td>[-0.007155741797977075, 0.03115255188318026, 0...</td>\n",
       "      <td>[0.0897931145172699, 0.0584418303878723, 0.039...</td>\n",
       "      <td>[0.1987986859438014, 0.1851467466124524, 0.106...</td>\n",
       "      <td>[0.05182955643047111, 0.05474124437626988, 0.0...</td>\n",
       "      <td>[0.022080853055407478, -0.005917636096386986, ...</td>\n",
       "      <td>[0.034017458448354604, 0.050848360926548736, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.10954147106059986, 0.09543707547448549, 0.1...</td>\n",
       "      <td>[0.08443238429455503, 0.11122536195200514, 0.1...</td>\n",
       "      <td>[0.1689079954466944, 0.15851380662874948, 0.16...</td>\n",
       "      <td>[0.10926529543883796, 0.13585122754038256, 0.1...</td>\n",
       "      <td>[0.11917602327208332, 0.1227674898280521, 0.14...</td>\n",
       "      <td>[0.0177040471441898, 0.03651202758746134, -0.0...</td>\n",
       "      <td>[0.10240827534030945, 0.13118533688654407, 0.0...</td>\n",
       "      <td>[0.0241722187244542, 0.09964264700539543, 0.03...</td>\n",
       "      <td>[0.073495533284772, 0.009173501646840311, 0.03...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.10749067559051856, 0.10173849360487047, 0.0...</td>\n",
       "      <td>[0.11590261156705806, 0.08388226232303925, 0.1...</td>\n",
       "      <td>[0.06943256292867704, 0.0788552329774304, 0.11...</td>\n",
       "      <td>[0.043278447804076615, 0.01391558845780019, 0....</td>\n",
       "      <td>[0.04362810094417316, 0.031905186522988585, 0....</td>\n",
       "      <td>[0.05643031750101332, 0.022797859563258294, 0....</td>\n",
       "      <td>[0.02524379636519308, -0.005077485995400918, -...</td>\n",
       "      <td>[0.12043632249306604, 0.1573976898906536, 0.18...</td>\n",
       "      <td>[0.11856583361728645, 0.15098107287055465, 0.1...</td>\n",
       "      <td>[0.0945960782518209, 0.06857057317565557, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                                  0  \\\n",
       "0         0  [0.1425291059511972, 0.1427490584012465, 0.064...   \n",
       "1         1  [0.09026107284806115, 0.06150244142972182, 0.0...   \n",
       "2         0  [0.10379803421266834, 0.03487742674994996, 0.0...   \n",
       "3         1  [0.06946228364788944, 0.09693821656515499, 0.1...   \n",
       "4         0  [0.07317925682411716, 0.04308888324317473, 0.0...   \n",
       "...     ...                                                ...   \n",
       "1995      1  [0.12493658141290107, 0.12689697375001657, 0.1...   \n",
       "1996      0  [0.04860533866349404, 0.006076427807596846, 0....   \n",
       "1997      1  [0.15497855978786215, 0.14595640349256533, 0.1...   \n",
       "1998      0  [0.01519477520271758, 0.003058235823519981, 0....   \n",
       "1999      1  [0.10954147106059986, 0.09543707547448549, 0.1...   \n",
       "\n",
       "                                                      1  \\\n",
       "0     [0.08610056879213501, 0.12178451887607245, 0.1...   \n",
       "1     [0.04538937670938503, 0.05308249335581676, 0.0...   \n",
       "2     [0.05241632620285876, 0.009666815823901349, -0...   \n",
       "3     [0.09832563902423447, 0.07066609313822994, 0.0...   \n",
       "4     [0.03933238723806587, 0.035817914239608006, 0....   \n",
       "...                                                 ...   \n",
       "1995  [0.059188699293574, 0.08272885373777021, 0.106...   \n",
       "1996  [0.0375482338236825, -0.004796497136600264, 0....   \n",
       "1997  [0.15015638649004998, 0.12473079907892935, 0.1...   \n",
       "1998  [0.2116208103744061, 0.19621462118841362, 0.18...   \n",
       "1999  [0.08443238429455503, 0.11122536195200514, 0.1...   \n",
       "\n",
       "                                                      2  \\\n",
       "0     [0.005027882676477292, 0.014423904255524037, -...   \n",
       "1     [0.11987957003036875, 0.1515483946939712, 0.11...   \n",
       "2     [0.03426888074694801, 0.05330306670983995, 0.0...   \n",
       "3     [0.045218165297132434, 0.0375920805571551, 0.0...   \n",
       "4     [0.018353812762015302, 0.021751701170880357, 0...   \n",
       "...                                                 ...   \n",
       "1995  [0.034189102695024384, 0.036194019765602235, 0...   \n",
       "1996  [-0.021410043433903788, 0.007444390920218594, ...   \n",
       "1997  [0.07338209574325391, 0.09258332717793114, 0.1...   \n",
       "1998  [0.097123607930022, 0.015435691085134335, 0.08...   \n",
       "1999  [0.1689079954466944, 0.15851380662874948, 0.16...   \n",
       "\n",
       "                                                      3  \\\n",
       "0     [0.11386409884702459, 0.03248970179094752, 0.0...   \n",
       "1     [0.09121350961371177, 0.0659840492358891, 0.11...   \n",
       "2     [0.0448579504495472, 0.012665274218030632, -0....   \n",
       "3     [0.05997075400652483, 0.0025540526755087126, 0...   \n",
       "4     [0.06205677339596287, 0.10661882526596095, 0.0...   \n",
       "...                                                 ...   \n",
       "1995  [0.062271430510493574, 0.06323048871686557, 0....   \n",
       "1996  [0.026928433517584338, 0.07413738669426406, 0....   \n",
       "1997  [-0.006147194705856647, 0.02095478271814918, -...   \n",
       "1998  [0.022273018490969777, 0.11487904236583324, 0....   \n",
       "1999  [0.10926529543883796, 0.13585122754038256, 0.1...   \n",
       "\n",
       "                                                      4  \\\n",
       "0     [-0.036309577127568146, -0.02121906611363441, ...   \n",
       "1     [0.16635251289056696, 0.1343653560776765, 0.10...   \n",
       "2     [0.1295437098904198, 0.06001705681827446, 0.08...   \n",
       "3     [0.10346367040198412, 0.07852072303922047, 0.1...   \n",
       "4     [0.11719792183880774, 0.0824210294777011, 0.11...   \n",
       "...                                                 ...   \n",
       "1995  [0.08840770765352546, 0.07532380744981028, 0.0...   \n",
       "1996  [0.08604201091054361, 0.09036525676510573, 0.0...   \n",
       "1997  [0.11453821225420323, 0.14541325162488494, 0.1...   \n",
       "1998  [0.0425772654754845, 0.03332029083938193, 0.03...   \n",
       "1999  [0.11917602327208332, 0.1227674898280521, 0.14...   \n",
       "\n",
       "                                                      5  \\\n",
       "0     [0.044602493983996155, 0.05995862866779936, 0....   \n",
       "1     [0.13503600246340933, 0.15183458098893846, 0.1...   \n",
       "2     [0.058584378280174626, 0.044242129859667106, 0...   \n",
       "3     [0.11391956226463648, 0.16234800047703712, 0.1...   \n",
       "4     [0.04484371412272097, 0.056542809789619834, 0....   \n",
       "...                                                 ...   \n",
       "1995  [0.045926471886868575, 0.0534375811830377, 0.0...   \n",
       "1996  [0.02353306081653777, 0.017643947845763355, 0....   \n",
       "1997  [0.07530986578459772, 0.05484522055153167, 0.0...   \n",
       "1998  [0.011614932229236978, -0.017606038827710373, ...   \n",
       "1999  [0.0177040471441898, 0.03651202758746134, -0.0...   \n",
       "\n",
       "                                                      6  \\\n",
       "0     [0.09334196057819108, 0.042253172799132765, 0....   \n",
       "1     [0.024411648392230555, 0.09079993641305957, 0....   \n",
       "2     [0.03571457501426369, 0.0054818679344868955, 0...   \n",
       "3     [0.09807316440294812, 0.0870695551620023, 0.04...   \n",
       "4     [0.03280576845666359, -0.02185083727878013, 0....   \n",
       "...                                                 ...   \n",
       "1995  [0.06296620305514036, 0.022889441448729415, 0....   \n",
       "1996  [0.17543667477893674, 0.17237662975654225, 0.1...   \n",
       "1997  [0.11361606807018054, 0.10088559727546198, 0.0...   \n",
       "1998  [0.0721453210167938, 0.02765562474166327, 0.02...   \n",
       "1999  [0.10240827534030945, 0.13118533688654407, 0.0...   \n",
       "\n",
       "                                                      7  \\\n",
       "0     [-0.010183451277868202, 0.01245298332715052, 0...   \n",
       "1     [0.07346185121773145, 0.099639496104335, 0.090...   \n",
       "2     [-0.01681491854523136, -0.021577889193778538, ...   \n",
       "3     [0.03834438717966448, -0.006503626931474042, 0...   \n",
       "4     [0.047304235633775026, 0.032387129456268614, 0...   \n",
       "...                                                 ...   \n",
       "1995  [0.05035404703234739, 0.029742635370106633, 0....   \n",
       "1996  [0.03352560451795513, 0.06512977191882435, 0.0...   \n",
       "1997  [0.06184192787995971, 0.07564282962688629, 0.1...   \n",
       "1998  [0.03467822376888466, 0.11483958752992302, 0.0...   \n",
       "1999  [0.0241722187244542, 0.09964264700539543, 0.03...   \n",
       "\n",
       "                                                      8  ...  \\\n",
       "0     [-0.02725731639487562, 0.019496893147104413, -...  ...   \n",
       "1     [0.010426223384971362, 0.03856450592151311, 0....  ...   \n",
       "2     [0.013671440346787841, 0.06960063313824948, 0....  ...   \n",
       "3     [0.02718891249089698, 0.06585193318954866, 0.0...  ...   \n",
       "4     [0.02474545172467214, 0.04227512884907455, 0.0...  ...   \n",
       "...                                                 ...  ...   \n",
       "1995  [0.0812417860374218, 0.061490101207917355, 0.0...  ...   \n",
       "1996  [0.010429266546777491, 0.03958361633422225, 0....  ...   \n",
       "1997  [0.05054253483519612, 0.055045897972012606, 0....  ...   \n",
       "1998  [0.10552556111479028, 0.040904221060112635, 0....  ...   \n",
       "1999  [0.073495533284772, 0.009173501646840311, 0.03...  ...   \n",
       "\n",
       "                                                     10  \\\n",
       "0     [-0.004370444473687236, 0.0012803431762743872,...   \n",
       "1     [0.18139046124944358, 0.12763791954767872, 0.1...   \n",
       "2     [-0.038046655138093875, -0.020977835432432496,...   \n",
       "3     [0.11494618854379515, 0.11719455190465707, 0.0...   \n",
       "4     [0.08763814000919284, 0.12003810135952675, 0.1...   \n",
       "...                                                 ...   \n",
       "1995  [0.0788604205383896, 0.12142890841649173, 0.11...   \n",
       "1996  [0.0978964493268017, 0.08159608608684248, 0.04...   \n",
       "1997  [0.125990966843816, 0.14429319597512696, 0.111...   \n",
       "1998  [0.00390743867216637, -0.018137976173359723, -...   \n",
       "1999  [0.10749067559051856, 0.10173849360487047, 0.0...   \n",
       "\n",
       "                                                     11  \\\n",
       "0     [-0.0008438477891762886, -0.016462048702332692...   \n",
       "1     [0.040863743652190226, 0.07501025908085429, 0....   \n",
       "2     [-0.01746827751205943, 0.04956841253120914, -0...   \n",
       "3     [0.08628512585459558, 0.059011228725845334, 0....   \n",
       "4     [0.02800378208319385, 0.001342310891320062, 0....   \n",
       "...                                                 ...   \n",
       "1995  [0.008275963496682628, 0.02585088367749012, 0....   \n",
       "1996  [0.032987301004670504, 0.06103057005537256, 0....   \n",
       "1997  [0.11855254163266152, 0.18141762838474443, 0.1...   \n",
       "1998  [-0.012064404194704226, 0.003779045510148467, ...   \n",
       "1999  [0.11590261156705806, 0.08388226232303925, 0.1...   \n",
       "\n",
       "                                                     12  \\\n",
       "0     [0.14279538847118695, 0.1504154664021815, 0.09...   \n",
       "1     [0.10976158723796357, 0.10558312438223087, 0.1...   \n",
       "2     [-0.02114032236145766, 0.06490861359079454, 0....   \n",
       "3     [-0.012603319937051407, 0.030363603721201397, ...   \n",
       "4     [0.04035642014640546, 0.08219495878636537, 0.0...   \n",
       "...                                                 ...   \n",
       "1995  [0.05995074681912563, 0.07491643506597612, 0.0...   \n",
       "1996  [0.047682049131733545, 0.03421068387204099, -0...   \n",
       "1997  [0.06275210604135785, 0.0342744585985594, 0.08...   \n",
       "1998  [0.08774569876570498, 0.00046272257541874005, ...   \n",
       "1999  [0.06943256292867704, 0.0788552329774304, 0.11...   \n",
       "\n",
       "                                                     13  \\\n",
       "0     [0.11294591510584956, 0.10190435072707164, 0.1...   \n",
       "1     [0.0377938173925821, 0.04197967886427428, 0.04...   \n",
       "2     [0.24609106121795798, 0.18074583987838458, 0.1...   \n",
       "3     [0.026195223606124553, 0.06392444261333008, 0....   \n",
       "4     [-0.0025751516308632275, -0.03355490706132226,...   \n",
       "...                                                 ...   \n",
       "1995  [0.07526386553249556, 0.04114470524258412, 0.0...   \n",
       "1996  [0.056831823089551696, 0.11313197152646642, 0....   \n",
       "1997  [0.03905791221125657, 0.07366135773538292, 0.0...   \n",
       "1998  [0.08805965871243143, 0.021387356567461747, 0....   \n",
       "1999  [0.043278447804076615, 0.01391558845780019, 0....   \n",
       "\n",
       "                                                     14  \\\n",
       "0     [0.04069369212513115, 0.05192730568117687, 0.0...   \n",
       "1     [0.06481156522533488, 0.0849914691623969, 0.05...   \n",
       "2     [0.026843031984688907, 0.05715441124286436, 0....   \n",
       "3     [0.023335795838676107, -0.002135853540557949, ...   \n",
       "4     [0.09145028671125861, 0.12359534550040212, 0.1...   \n",
       "...                                                 ...   \n",
       "1995  [0.07433706446941468, 0.052957708636133555, 0....   \n",
       "1996  [0.047918206642892085, 0.009353498377265432, 0...   \n",
       "1997  [0.06080626260930224, 0.07671166299132559, 0.1...   \n",
       "1998  [-0.007155741797977075, 0.03115255188318026, 0...   \n",
       "1999  [0.04362810094417316, 0.031905186522988585, 0....   \n",
       "\n",
       "                                                     15  \\\n",
       "0     [0.17146587360301205, 0.1516378956918845, 0.13...   \n",
       "1     [0.08622352814126706, 0.08594728731593484, 0.1...   \n",
       "2     [0.07468277961919811, 0.06741454661969365, 0.0...   \n",
       "3     [0.11010470502185954, 0.10939339996580533, 0.1...   \n",
       "4     [0.03424462582179037, 0.02599719607520608, 0.0...   \n",
       "...                                                 ...   \n",
       "1995  [0.09115784757681866, 0.1004452551735828, 0.04...   \n",
       "1996  [0.03333462589460928, 0.046663450804679596, -0...   \n",
       "1997  [0.10595094121876673, 0.09895953288301954, 0.1...   \n",
       "1998  [0.0897931145172699, 0.0584418303878723, 0.039...   \n",
       "1999  [0.05643031750101332, 0.022797859563258294, 0....   \n",
       "\n",
       "                                                     16  \\\n",
       "0     [0.052388034258788685, 0.007397828903799072, 0...   \n",
       "1     [0.08705411374511021, 0.15051393652211248, 0.1...   \n",
       "2     [0.06148104835203988, 0.07690584646783945, 0.0...   \n",
       "3     [0.12337461495884046, 0.06555766431303268, 0.0...   \n",
       "4     [0.07316866563213471, 0.03120491294503651, 0.0...   \n",
       "...                                                 ...   \n",
       "1995  [0.07452955252660931, 0.09078906782969468, 0.0...   \n",
       "1996  [0.16285263053567656, 0.1999079442196383, 0.17...   \n",
       "1997  [0.14283868481305545, 0.13659785117346201, 0.0...   \n",
       "1998  [0.1987986859438014, 0.1851467466124524, 0.106...   \n",
       "1999  [0.02524379636519308, -0.005077485995400918, -...   \n",
       "\n",
       "                                                     17  \\\n",
       "0     [0.05133338291285723, -0.01201405857699753, 0....   \n",
       "1     [0.14209529176817465, 0.15320980344275378, 0.1...   \n",
       "2     [0.0038222565040456962, 0.05009315363189586, 0...   \n",
       "3     [0.11930642522793342, 0.10306962102384157, 0.1...   \n",
       "4     [0.07245593076891103, 0.07517045955627918, 0.0...   \n",
       "...                                                 ...   \n",
       "1995  [0.039728744938438657, 0.021819043882844422, 0...   \n",
       "1996  [0.0022758915635143484, 0.016323449067340262, ...   \n",
       "1997  [0.0654320176103439, 0.03301065580908678, 0.06...   \n",
       "1998  [0.05182955643047111, 0.05474124437626988, 0.0...   \n",
       "1999  [0.12043632249306604, 0.1573976898906536, 0.18...   \n",
       "\n",
       "                                                     18  \\\n",
       "0     [0.041525543436852545, -0.011103649970985126, ...   \n",
       "1     [0.1358522869401525, 0.1233307187259513, 0.076...   \n",
       "2     [0.05951629244044407, 0.016282464377705187, 0....   \n",
       "3     [0.1203724099958524, 0.1362173487217062, 0.141...   \n",
       "4     [0.17693769273899201, 0.14398669290619506, 0.1...   \n",
       "...                                                 ...   \n",
       "1995  [0.04494585172002373, 0.05542943762681147, 0.0...   \n",
       "1996  [0.06500477451488632, 0.050653981466706396, 0....   \n",
       "1997  [0.11855149179931594, 0.07580638241162788, 0.1...   \n",
       "1998  [0.022080853055407478, -0.005917636096386986, ...   \n",
       "1999  [0.11856583361728645, 0.15098107287055465, 0.1...   \n",
       "\n",
       "                                                     19  \n",
       "0     [0.04349728067940602, 0.01602649069027814, 0.0...  \n",
       "1     [0.11515842269915107, 0.08387805282589375, 0.1...  \n",
       "2     [0.049718757651829544, 0.03751878346120866, 0....  \n",
       "3     [0.029218288979118448, 0.0009392166636504121, ...  \n",
       "4     [0.030750248484464053, 0.04810908861741681, 0....  \n",
       "...                                                 ...  \n",
       "1995  [0.11593676641571117, 0.09713573312622881, 0.1...  \n",
       "1996  [0.040542859090054485, 0.014000753423258537, 0...  \n",
       "1997  [0.09749568264469863, 0.12940440408733556, 0.1...  \n",
       "1998  [0.034017458448354604, 0.050848360926548736, -...  \n",
       "1999  [0.0945960782518209, 0.06857057317565557, 0.03...  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31af7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fbaa8cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a = df[df[\"label\"] == 0]\n",
    "a[\"sum_temp\"] = a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb3e4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reset_index()\n",
    "a = a.drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8a4c4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_a = []\n",
    "for i in range(len(a)):\n",
    "    sums_a.append(a.loc[i][\"sum_temp\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3bc9e63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.980381664966583"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sums_a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2ae1142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "b = df[df[\"label\"] == 1]\n",
    "b[\"sum_temp\"] = b.drop([\"label\"], axis=1).sum(axis=1)\n",
    "b = b.reset_index()\n",
    "b = b.drop([\"index\"],axis=1)\n",
    "sums_b = []\n",
    "for i in range(len(b)):\n",
    "    sums_b.append(b.loc[i][\"sum_temp\"].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eb75df6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.82490990378987"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sums_b).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "feae97f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35268/1964477611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df.drop([\"index\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1969026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(set(df.columns) - set([\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5134530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "cols = list(set(df.columns) - set([\"label\"]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[cols], df[\"label\"], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e82cbd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>[0.1381175742240148, 0.18246896937746604, 0.17...</td>\n",
       "      <td>[0.12502888486835956, 0.12510784327963093, 0.1...</td>\n",
       "      <td>[0.054059678223498914, 0.01350734163998104, 0....</td>\n",
       "      <td>[0.03406721414907447, 0.008442675120333594, 0....</td>\n",
       "      <td>[0.045291874395072235, 0.03826346577865515, 0....</td>\n",
       "      <td>[0.08244197777304661, 0.06770669557363877, 0.0...</td>\n",
       "      <td>[0.12293123398311531, 0.11740541886148707, 0.0...</td>\n",
       "      <td>[0.11285799116033948, 0.08862335426259732, 0.1...</td>\n",
       "      <td>[0.10932380052055721, 0.13105768227796755, 0.1...</td>\n",
       "      <td>[0.03375288060891351, 0.03847962317710875, 0.0...</td>\n",
       "      <td>[0.11982506962459827, 0.10142032407379237, 0.0...</td>\n",
       "      <td>[0.07166068512173661, 0.12732779958590068, 0.0...</td>\n",
       "      <td>[0.07957142986477199, 0.04945087896111627, 0.0...</td>\n",
       "      <td>[0.04952175718124144, 0.06565742080792214, 0.1...</td>\n",
       "      <td>[0.10676000798359503, 0.1352265550199152, 0.16...</td>\n",
       "      <td>[0.06702976130612603, 0.0954466221085365, 0.08...</td>\n",
       "      <td>[0.10614167247593251, 0.07291824368302306, 0.0...</td>\n",
       "      <td>[0.061992768222163874, 0.05333033446091844, 0....</td>\n",
       "      <td>[0.09182678788742905, 0.08682577657065811, 0.0...</td>\n",
       "      <td>[0.13398475225360676, 0.08897964417495526, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>[0.0781667933435439, 0.10753365267868917, 0.13...</td>\n",
       "      <td>[0.08839983132142593, 0.06042362920685088, 0.0...</td>\n",
       "      <td>[-0.003609773055885883, 0.007536980657965146, ...</td>\n",
       "      <td>[0.08483716673442984, 0.07727727002956775, 0.0...</td>\n",
       "      <td>[-0.0037146277862335347, 0.05007698882773209, ...</td>\n",
       "      <td>[-0.025085415225305066, 0.01117086871383359, -...</td>\n",
       "      <td>[-0.006011277140002651, -0.028368284815269717,...</td>\n",
       "      <td>[0.03490137317215554, 0.04595000088249253, 0.0...</td>\n",
       "      <td>[-0.009531211675701512, -0.009834703768637142,...</td>\n",
       "      <td>[0.07225181187965317, 0.07546857374931731, 0.0...</td>\n",
       "      <td>[0.059987353373799394, -0.004749498572639586, ...</td>\n",
       "      <td>[0.011477531877203857, 0.026300315398498433, 0...</td>\n",
       "      <td>[0.08240424241778026, 0.025431222409592412, -0...</td>\n",
       "      <td>[0.11691693837562175, 0.051498155521268615, 0....</td>\n",
       "      <td>[0.23636279075585565, 0.18462696408895643, 0.1...</td>\n",
       "      <td>[0.03444901493473503, -0.02363062946580162, 0....</td>\n",
       "      <td>[0.0010415763325745328, -0.001213159599028752,...</td>\n",
       "      <td>[0.011730557912886238, 0.04428525576725784, 0....</td>\n",
       "      <td>[-0.0071883945090362895, 0.045028241497329397,...</td>\n",
       "      <td>[0.15097594176868176, 0.16359982051452993, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>[-0.0065549237765433616, -0.006576215549823045...</td>\n",
       "      <td>[-0.0009308713248654, -0.008580535447022721, -...</td>\n",
       "      <td>[0.07433839646214, 0.09498987962977523, 0.0515...</td>\n",
       "      <td>[0.04019576052633455, 0.05648835347914022, 0.0...</td>\n",
       "      <td>[0.005221244432895504, 0.05287768535908717, -0...</td>\n",
       "      <td>[0.07186383193510937, 0.07714045698641964, 0.0...</td>\n",
       "      <td>[0.03271163208317724, -0.0005552054825968995, ...</td>\n",
       "      <td>[0.023295177013200198, -0.03322157630857359, 0...</td>\n",
       "      <td>[0.001405286581873888, 0.02939311142497595, 0....</td>\n",
       "      <td>[-0.004366727418723244, 0.057925541606211786, ...</td>\n",
       "      <td>[0.05110926891414844, 0.0775396394884463, 0.05...</td>\n",
       "      <td>[-0.023845373091617474, 0.06171028828629014, -...</td>\n",
       "      <td>[0.006319688940490865, 0.03452642172987756, 0....</td>\n",
       "      <td>[0.005526510672793208, 0.03273465445899947, -0...</td>\n",
       "      <td>[0.07166008142740465, 0.047778338503419115, 0....</td>\n",
       "      <td>[0.1227195878695772, 0.07365038036091497, 0.13...</td>\n",
       "      <td>[0.031719475578899536, 0.05184732744391414, -0...</td>\n",
       "      <td>[0.17889951272079263, 0.2003681779675323, 0.20...</td>\n",
       "      <td>[0.09301336645181826, 0.09264389061209766, 0.1...</td>\n",
       "      <td>[0.12163181568864329, 0.11755752035043009, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>[0.048870234613590156, 0.07600353928393161, 0....</td>\n",
       "      <td>[0.06890774630881179, 0.09390576396630938, 0.0...</td>\n",
       "      <td>[0.15096686689999111, 0.11403928600967433, 0.0...</td>\n",
       "      <td>[-0.03936673762636673, -0.04736765845251291, 0...</td>\n",
       "      <td>[0.11000485225891614, 0.0843747714213444, 0.10...</td>\n",
       "      <td>[0.08014212005484112, 0.0691224840627305, 0.00...</td>\n",
       "      <td>[-0.02891532604996815, 0.00981093236960838, 0....</td>\n",
       "      <td>[0.06091373378790503, -0.016852918825652777, 0...</td>\n",
       "      <td>[0.16273424809189596, 0.2113761174788802, 0.14...</td>\n",
       "      <td>[-0.005568424669660666, 0.025883069984955254, ...</td>\n",
       "      <td>[0.05295230620031262, 0.050397392304422584, -0...</td>\n",
       "      <td>[-0.024108802631536665, 0.04109684698377147, 0...</td>\n",
       "      <td>[0.12172525206047098, 0.12296737757797715, 0.1...</td>\n",
       "      <td>[0.04813216604077485, 0.026131750575260605, 0....</td>\n",
       "      <td>[-0.009835293598469075, 0.0020547030896352, 0....</td>\n",
       "      <td>[0.08295863568262693, 0.07835182580882857, 0.0...</td>\n",
       "      <td>[0.11666549997208643, 0.1483304373672984, 0.15...</td>\n",
       "      <td>[0.011511348004738547, 0.0019885710634519396, ...</td>\n",
       "      <td>[-0.009203023971486323, 0.049320054094552854, ...</td>\n",
       "      <td>[-0.013720402705653709, 0.010060120869738592, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>[0.14594033163508163, 0.11727797338143553, 0.1...</td>\n",
       "      <td>[0.11015311333579798, 0.12879946999219072, 0.0...</td>\n",
       "      <td>[0.08830366098833992, 0.0258578284789868, 0.04...</td>\n",
       "      <td>[0.14523224794059864, 0.15602627728065882, 0.1...</td>\n",
       "      <td>[0.17431196769883162, 0.12213777658903427, 0.1...</td>\n",
       "      <td>[0.0193269801649178, 0.01961688288374135, -0.0...</td>\n",
       "      <td>[0.11738637817940467, 0.1164055118642528, 0.14...</td>\n",
       "      <td>[0.0552293468527364, 0.02101633617879167, 0.04...</td>\n",
       "      <td>[0.022852865759126, 0.023213797206002244, 0.02...</td>\n",
       "      <td>[0.030411211660821093, 0.043365678235422214, 0...</td>\n",
       "      <td>[0.11461857406682936, 0.10697134038146738, 0.1...</td>\n",
       "      <td>[0.052816662739617784, 0.07922226718164864, 0....</td>\n",
       "      <td>[0.05921904276143573, 0.04775878899272906, 0.0...</td>\n",
       "      <td>[0.07952277380171989, 0.09904390191622803, 0.0...</td>\n",
       "      <td>[0.06612189992800424, 0.04223707175027987, 0.0...</td>\n",
       "      <td>[0.03978380724018162, 0.03082718348579546, 0.0...</td>\n",
       "      <td>[0.06702289153132387, 0.08597097986134394, 0.0...</td>\n",
       "      <td>[0.12614030653994351, 0.12605561923176406, 0.1...</td>\n",
       "      <td>[0.13915350456031123, 0.0821819543346081, 0.15...</td>\n",
       "      <td>[0.13554818644886246, 0.13063503342271954, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.03987705402475159, -0.014803529801810624, 0...</td>\n",
       "      <td>[0.021904535916587017, 0.041099448887216464, 0...</td>\n",
       "      <td>[0.022411751063897582, 0.0691701863917391, 0.0...</td>\n",
       "      <td>[0.1041476951514097, 0.0892465595618195, 0.086...</td>\n",
       "      <td>[0.18260301098757453, 0.18227627017593628, 0.1...</td>\n",
       "      <td>[0.05077418442300215, 0.057362152909070485, 0....</td>\n",
       "      <td>[0.07232979726421246, 0.0835893880213675, 0.06...</td>\n",
       "      <td>[0.0660355113444574, 0.018308549136542347, 0.0...</td>\n",
       "      <td>[0.14739023565300247, 0.09014304235068676, 0.0...</td>\n",
       "      <td>[-0.03837543451888809, 0.0523516648318249, -0....</td>\n",
       "      <td>[0.13528147163542598, 0.17340993424955686, 0.1...</td>\n",
       "      <td>[0.05273780606213225, -0.007819586610951057, 0...</td>\n",
       "      <td>[0.10121928866470886, 0.055896919048174135, 0....</td>\n",
       "      <td>[0.010569013988966442, 0.06079932436766133, 0....</td>\n",
       "      <td>[0.005163662803639113, -0.007902433662855389, ...</td>\n",
       "      <td>[0.1975184775142403, 0.18187000759027766, 0.13...</td>\n",
       "      <td>[0.03965852338819514, 0.03847887551587167, 0.0...</td>\n",
       "      <td>[0.1438234561847188, 0.10453966171712024, 0.14...</td>\n",
       "      <td>[0.030962552476900246, 0.031069376147055544, 0...</td>\n",
       "      <td>[0.050657742496200704, -0.0258879786932455, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>[0.05226567306903687, 0.09182595685621826, 0.1...</td>\n",
       "      <td>[0.13181008152843615, 0.0909313923875416, 0.10...</td>\n",
       "      <td>[0.07890335206381727, 0.1095725721841452, 0.06...</td>\n",
       "      <td>[0.15369355474461482, 0.13247551889342823, 0.1...</td>\n",
       "      <td>[0.10086967997826442, 0.11077290928131216, 0.1...</td>\n",
       "      <td>[0.07033370599405511, 0.12381835888398596, 0.0...</td>\n",
       "      <td>[0.0011088402713520067, 0.04755664884886901, 0...</td>\n",
       "      <td>[0.1844556362649592, 0.1249586552520488, 0.122...</td>\n",
       "      <td>[0.16902801590691488, 0.14185361078826664, 0.1...</td>\n",
       "      <td>[0.059437340018078946, 0.027580223890794512, 0...</td>\n",
       "      <td>[0.11633042099926971, 0.05460572565837464, 0.0...</td>\n",
       "      <td>[0.08044152254722942, 0.07617143837130103, 0.1...</td>\n",
       "      <td>[0.07700280830955893, 0.10548981074310973, 0.1...</td>\n",
       "      <td>[0.06243216619685195, 0.01499947131912725, 0.0...</td>\n",
       "      <td>[0.0749673832424401, 0.11344816950968292, 0.11...</td>\n",
       "      <td>[0.06575425986546093, 0.008815140896914398, 0....</td>\n",
       "      <td>[0.15691693161289388, 0.12343233818398494, 0.1...</td>\n",
       "      <td>[0.005280289497362639, 0.04404464191903978, 0....</td>\n",
       "      <td>[0.06312590894646136, 0.06266121777444324, 0.0...</td>\n",
       "      <td>[0.06965787767874532, 0.05984104508522715, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>[0.058551786747360286, 0.05120613949103428, 0....</td>\n",
       "      <td>[0.06283299314972482, 0.009288243499403229, -0...</td>\n",
       "      <td>[0.05989711613189461, 0.030334465091080995, 0....</td>\n",
       "      <td>[0.008169703989609763, 0.01129429033092258, 0....</td>\n",
       "      <td>[0.06006364713167141, 0.003220507353033964, 0....</td>\n",
       "      <td>[0.031989802110787384, 0.0008714410381162711, ...</td>\n",
       "      <td>[0.07961304177673857, 0.02786931078483567, 0.0...</td>\n",
       "      <td>[0.02712660008874608, 0.021038843201600196, 0....</td>\n",
       "      <td>[0.008119552804015738, 0.015804628231627475, 0...</td>\n",
       "      <td>[-0.023985822374981283, 0.07051754244477479, 0...</td>\n",
       "      <td>[0.28457939865005494, 0.3487702941060944, 0.27...</td>\n",
       "      <td>[0.052819947579707566, 0.028894418851550488, 0...</td>\n",
       "      <td>[0.03375685211786811, 0.09084294876371737, 0.1...</td>\n",
       "      <td>[0.05423192315131732, 0.07731510818807837, 0.0...</td>\n",
       "      <td>[0.048754791781123276, -0.010532678310044431, ...</td>\n",
       "      <td>[-0.009389868114192564, 0.05626463123626152, -...</td>\n",
       "      <td>[0.026839350527689654, 0.03126140783026943, 0....</td>\n",
       "      <td>[0.0693982227406164, 0.034726979958988186, 0.0...</td>\n",
       "      <td>[0.04819278460123301, 0.07106711834354168, 0.0...</td>\n",
       "      <td>[0.06793961065522333, 0.061068797322317944, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>[0.1183333363271008, 0.1180033920746583, 0.124...</td>\n",
       "      <td>[0.02814167652521523, 0.039959824074780534, 0....</td>\n",
       "      <td>[0.003243759752555829, 0.00150549581007434, 0....</td>\n",
       "      <td>[0.08678192083750383, 0.1100619527698935, 0.13...</td>\n",
       "      <td>[0.1084893071047685, 0.06931766273345519, 0.05...</td>\n",
       "      <td>[0.019990923565978303, 0.0072675505131122725, ...</td>\n",
       "      <td>[0.029247507963470556, -0.010804277777453863, ...</td>\n",
       "      <td>[0.09588905059047098, 0.10089132002749845, 0.0...</td>\n",
       "      <td>[0.06820362987627451, 0.0615340171890625, 0.04...</td>\n",
       "      <td>[0.08851386138299144, 0.02690292847183012, 0.0...</td>\n",
       "      <td>[0.00301597611833431, 0.03628396707677197, 0.0...</td>\n",
       "      <td>[0.08707040517784029, 0.07177328956339678, 0.0...</td>\n",
       "      <td>[0.05382201126813172, 0.01983780171171057, 0.0...</td>\n",
       "      <td>[0.0686896062690532, 0.05545814696114496, 0.05...</td>\n",
       "      <td>[0.02340644303417705, -0.02244674771279879, -0...</td>\n",
       "      <td>[0.06958524365995945, 0.07448553631232019, 0.0...</td>\n",
       "      <td>[0.03388775903802498, 0.06887939181420141, 0.0...</td>\n",
       "      <td>[-0.002023080393315304, 0.03167344931961571, -...</td>\n",
       "      <td>[0.07084763160393513, 0.05575328993518228, 0.0...</td>\n",
       "      <td>[0.045310632263221816, 0.03262440132974497, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>[0.10923811183245911, 0.1135572137978453, 0.14...</td>\n",
       "      <td>[0.07974411897377619, 0.07928853568426335, 0.1...</td>\n",
       "      <td>[0.00028724349275308786, -0.016812828419004756...</td>\n",
       "      <td>[0.0018988476522899009, 0.08969238554880202, 0...</td>\n",
       "      <td>[0.12783024586487943, 0.12218746052754677, 0.0...</td>\n",
       "      <td>[0.009216218500993245, 0.02170864168225141, -0...</td>\n",
       "      <td>[-0.0015651155466553518, 0.027339654909386488,...</td>\n",
       "      <td>[0.030424524465503394, 0.007640631405723866, 0...</td>\n",
       "      <td>[0.1164842851388584, 0.1354183484430304, 0.135...</td>\n",
       "      <td>[0.10307268142729731, 0.12730680512372278, 0.0...</td>\n",
       "      <td>[0.03678601214661547, 0.06358759750434732, 0.0...</td>\n",
       "      <td>[0.035114853934142334, 0.05065742660893304, 0....</td>\n",
       "      <td>[-0.0003936391741312952, 0.06790408196792258, ...</td>\n",
       "      <td>[0.09127649158768107, 0.06543609883761982, 0.1...</td>\n",
       "      <td>[0.14691123434225106, 0.14335331038382687, 0.1...</td>\n",
       "      <td>[0.020000371252096437, 0.015554615316314246, 0...</td>\n",
       "      <td>[0.03549430492814642, 0.04634538387306506, -0....</td>\n",
       "      <td>[0.053428776541316045, 0.03317379010214638, 0....</td>\n",
       "      <td>[0.14241755689762844, 0.07511459318944892, 0.1...</td>\n",
       "      <td>[0.022331081815912233, 0.05484102672682166, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "315   [0.1381175742240148, 0.18246896937746604, 0.17...   \n",
       "1418  [0.0781667933435439, 0.10753365267868917, 0.13...   \n",
       "1586  [-0.0065549237765433616, -0.006576215549823045...   \n",
       "1304  [0.048870234613590156, 0.07600353928393161, 0....   \n",
       "1403  [0.14594033163508163, 0.11727797338143553, 0.1...   \n",
       "...                                                 ...   \n",
       "19    [0.03987705402475159, -0.014803529801810624, 0...   \n",
       "659   [0.05226567306903687, 0.09182595685621826, 0.1...   \n",
       "1172  [0.058551786747360286, 0.05120613949103428, 0....   \n",
       "592   [0.1183333363271008, 0.1180033920746583, 0.124...   \n",
       "653   [0.10923811183245911, 0.1135572137978453, 0.14...   \n",
       "\n",
       "                                                      1  \\\n",
       "315   [0.12502888486835956, 0.12510784327963093, 0.1...   \n",
       "1418  [0.08839983132142593, 0.06042362920685088, 0.0...   \n",
       "1586  [-0.0009308713248654, -0.008580535447022721, -...   \n",
       "1304  [0.06890774630881179, 0.09390576396630938, 0.0...   \n",
       "1403  [0.11015311333579798, 0.12879946999219072, 0.0...   \n",
       "...                                                 ...   \n",
       "19    [0.021904535916587017, 0.041099448887216464, 0...   \n",
       "659   [0.13181008152843615, 0.0909313923875416, 0.10...   \n",
       "1172  [0.06283299314972482, 0.009288243499403229, -0...   \n",
       "592   [0.02814167652521523, 0.039959824074780534, 0....   \n",
       "653   [0.07974411897377619, 0.07928853568426335, 0.1...   \n",
       "\n",
       "                                                      2  \\\n",
       "315   [0.054059678223498914, 0.01350734163998104, 0....   \n",
       "1418  [-0.003609773055885883, 0.007536980657965146, ...   \n",
       "1586  [0.07433839646214, 0.09498987962977523, 0.0515...   \n",
       "1304  [0.15096686689999111, 0.11403928600967433, 0.0...   \n",
       "1403  [0.08830366098833992, 0.0258578284789868, 0.04...   \n",
       "...                                                 ...   \n",
       "19    [0.022411751063897582, 0.0691701863917391, 0.0...   \n",
       "659   [0.07890335206381727, 0.1095725721841452, 0.06...   \n",
       "1172  [0.05989711613189461, 0.030334465091080995, 0....   \n",
       "592   [0.003243759752555829, 0.00150549581007434, 0....   \n",
       "653   [0.00028724349275308786, -0.016812828419004756...   \n",
       "\n",
       "                                                      3  \\\n",
       "315   [0.03406721414907447, 0.008442675120333594, 0....   \n",
       "1418  [0.08483716673442984, 0.07727727002956775, 0.0...   \n",
       "1586  [0.04019576052633455, 0.05648835347914022, 0.0...   \n",
       "1304  [-0.03936673762636673, -0.04736765845251291, 0...   \n",
       "1403  [0.14523224794059864, 0.15602627728065882, 0.1...   \n",
       "...                                                 ...   \n",
       "19    [0.1041476951514097, 0.0892465595618195, 0.086...   \n",
       "659   [0.15369355474461482, 0.13247551889342823, 0.1...   \n",
       "1172  [0.008169703989609763, 0.01129429033092258, 0....   \n",
       "592   [0.08678192083750383, 0.1100619527698935, 0.13...   \n",
       "653   [0.0018988476522899009, 0.08969238554880202, 0...   \n",
       "\n",
       "                                                      4  \\\n",
       "315   [0.045291874395072235, 0.03826346577865515, 0....   \n",
       "1418  [-0.0037146277862335347, 0.05007698882773209, ...   \n",
       "1586  [0.005221244432895504, 0.05287768535908717, -0...   \n",
       "1304  [0.11000485225891614, 0.0843747714213444, 0.10...   \n",
       "1403  [0.17431196769883162, 0.12213777658903427, 0.1...   \n",
       "...                                                 ...   \n",
       "19    [0.18260301098757453, 0.18227627017593628, 0.1...   \n",
       "659   [0.10086967997826442, 0.11077290928131216, 0.1...   \n",
       "1172  [0.06006364713167141, 0.003220507353033964, 0....   \n",
       "592   [0.1084893071047685, 0.06931766273345519, 0.05...   \n",
       "653   [0.12783024586487943, 0.12218746052754677, 0.0...   \n",
       "\n",
       "                                                      5  \\\n",
       "315   [0.08244197777304661, 0.06770669557363877, 0.0...   \n",
       "1418  [-0.025085415225305066, 0.01117086871383359, -...   \n",
       "1586  [0.07186383193510937, 0.07714045698641964, 0.0...   \n",
       "1304  [0.08014212005484112, 0.0691224840627305, 0.00...   \n",
       "1403  [0.0193269801649178, 0.01961688288374135, -0.0...   \n",
       "...                                                 ...   \n",
       "19    [0.05077418442300215, 0.057362152909070485, 0....   \n",
       "659   [0.07033370599405511, 0.12381835888398596, 0.0...   \n",
       "1172  [0.031989802110787384, 0.0008714410381162711, ...   \n",
       "592   [0.019990923565978303, 0.0072675505131122725, ...   \n",
       "653   [0.009216218500993245, 0.02170864168225141, -0...   \n",
       "\n",
       "                                                      6  \\\n",
       "315   [0.12293123398311531, 0.11740541886148707, 0.0...   \n",
       "1418  [-0.006011277140002651, -0.028368284815269717,...   \n",
       "1586  [0.03271163208317724, -0.0005552054825968995, ...   \n",
       "1304  [-0.02891532604996815, 0.00981093236960838, 0....   \n",
       "1403  [0.11738637817940467, 0.1164055118642528, 0.14...   \n",
       "...                                                 ...   \n",
       "19    [0.07232979726421246, 0.0835893880213675, 0.06...   \n",
       "659   [0.0011088402713520067, 0.04755664884886901, 0...   \n",
       "1172  [0.07961304177673857, 0.02786931078483567, 0.0...   \n",
       "592   [0.029247507963470556, -0.010804277777453863, ...   \n",
       "653   [-0.0015651155466553518, 0.027339654909386488,...   \n",
       "\n",
       "                                                      7  \\\n",
       "315   [0.11285799116033948, 0.08862335426259732, 0.1...   \n",
       "1418  [0.03490137317215554, 0.04595000088249253, 0.0...   \n",
       "1586  [0.023295177013200198, -0.03322157630857359, 0...   \n",
       "1304  [0.06091373378790503, -0.016852918825652777, 0...   \n",
       "1403  [0.0552293468527364, 0.02101633617879167, 0.04...   \n",
       "...                                                 ...   \n",
       "19    [0.0660355113444574, 0.018308549136542347, 0.0...   \n",
       "659   [0.1844556362649592, 0.1249586552520488, 0.122...   \n",
       "1172  [0.02712660008874608, 0.021038843201600196, 0....   \n",
       "592   [0.09588905059047098, 0.10089132002749845, 0.0...   \n",
       "653   [0.030424524465503394, 0.007640631405723866, 0...   \n",
       "\n",
       "                                                      8  \\\n",
       "315   [0.10932380052055721, 0.13105768227796755, 0.1...   \n",
       "1418  [-0.009531211675701512, -0.009834703768637142,...   \n",
       "1586  [0.001405286581873888, 0.02939311142497595, 0....   \n",
       "1304  [0.16273424809189596, 0.2113761174788802, 0.14...   \n",
       "1403  [0.022852865759126, 0.023213797206002244, 0.02...   \n",
       "...                                                 ...   \n",
       "19    [0.14739023565300247, 0.09014304235068676, 0.0...   \n",
       "659   [0.16902801590691488, 0.14185361078826664, 0.1...   \n",
       "1172  [0.008119552804015738, 0.015804628231627475, 0...   \n",
       "592   [0.06820362987627451, 0.0615340171890625, 0.04...   \n",
       "653   [0.1164842851388584, 0.1354183484430304, 0.135...   \n",
       "\n",
       "                                                      9  \\\n",
       "315   [0.03375288060891351, 0.03847962317710875, 0.0...   \n",
       "1418  [0.07225181187965317, 0.07546857374931731, 0.0...   \n",
       "1586  [-0.004366727418723244, 0.057925541606211786, ...   \n",
       "1304  [-0.005568424669660666, 0.025883069984955254, ...   \n",
       "1403  [0.030411211660821093, 0.043365678235422214, 0...   \n",
       "...                                                 ...   \n",
       "19    [-0.03837543451888809, 0.0523516648318249, -0....   \n",
       "659   [0.059437340018078946, 0.027580223890794512, 0...   \n",
       "1172  [-0.023985822374981283, 0.07051754244477479, 0...   \n",
       "592   [0.08851386138299144, 0.02690292847183012, 0.0...   \n",
       "653   [0.10307268142729731, 0.12730680512372278, 0.0...   \n",
       "\n",
       "                                                     10  \\\n",
       "315   [0.11982506962459827, 0.10142032407379237, 0.0...   \n",
       "1418  [0.059987353373799394, -0.004749498572639586, ...   \n",
       "1586  [0.05110926891414844, 0.0775396394884463, 0.05...   \n",
       "1304  [0.05295230620031262, 0.050397392304422584, -0...   \n",
       "1403  [0.11461857406682936, 0.10697134038146738, 0.1...   \n",
       "...                                                 ...   \n",
       "19    [0.13528147163542598, 0.17340993424955686, 0.1...   \n",
       "659   [0.11633042099926971, 0.05460572565837464, 0.0...   \n",
       "1172  [0.28457939865005494, 0.3487702941060944, 0.27...   \n",
       "592   [0.00301597611833431, 0.03628396707677197, 0.0...   \n",
       "653   [0.03678601214661547, 0.06358759750434732, 0.0...   \n",
       "\n",
       "                                                     11  \\\n",
       "315   [0.07166068512173661, 0.12732779958590068, 0.0...   \n",
       "1418  [0.011477531877203857, 0.026300315398498433, 0...   \n",
       "1586  [-0.023845373091617474, 0.06171028828629014, -...   \n",
       "1304  [-0.024108802631536665, 0.04109684698377147, 0...   \n",
       "1403  [0.052816662739617784, 0.07922226718164864, 0....   \n",
       "...                                                 ...   \n",
       "19    [0.05273780606213225, -0.007819586610951057, 0...   \n",
       "659   [0.08044152254722942, 0.07617143837130103, 0.1...   \n",
       "1172  [0.052819947579707566, 0.028894418851550488, 0...   \n",
       "592   [0.08707040517784029, 0.07177328956339678, 0.0...   \n",
       "653   [0.035114853934142334, 0.05065742660893304, 0....   \n",
       "\n",
       "                                                     12  \\\n",
       "315   [0.07957142986477199, 0.04945087896111627, 0.0...   \n",
       "1418  [0.08240424241778026, 0.025431222409592412, -0...   \n",
       "1586  [0.006319688940490865, 0.03452642172987756, 0....   \n",
       "1304  [0.12172525206047098, 0.12296737757797715, 0.1...   \n",
       "1403  [0.05921904276143573, 0.04775878899272906, 0.0...   \n",
       "...                                                 ...   \n",
       "19    [0.10121928866470886, 0.055896919048174135, 0....   \n",
       "659   [0.07700280830955893, 0.10548981074310973, 0.1...   \n",
       "1172  [0.03375685211786811, 0.09084294876371737, 0.1...   \n",
       "592   [0.05382201126813172, 0.01983780171171057, 0.0...   \n",
       "653   [-0.0003936391741312952, 0.06790408196792258, ...   \n",
       "\n",
       "                                                     13  \\\n",
       "315   [0.04952175718124144, 0.06565742080792214, 0.1...   \n",
       "1418  [0.11691693837562175, 0.051498155521268615, 0....   \n",
       "1586  [0.005526510672793208, 0.03273465445899947, -0...   \n",
       "1304  [0.04813216604077485, 0.026131750575260605, 0....   \n",
       "1403  [0.07952277380171989, 0.09904390191622803, 0.0...   \n",
       "...                                                 ...   \n",
       "19    [0.010569013988966442, 0.06079932436766133, 0....   \n",
       "659   [0.06243216619685195, 0.01499947131912725, 0.0...   \n",
       "1172  [0.05423192315131732, 0.07731510818807837, 0.0...   \n",
       "592   [0.0686896062690532, 0.05545814696114496, 0.05...   \n",
       "653   [0.09127649158768107, 0.06543609883761982, 0.1...   \n",
       "\n",
       "                                                     14  \\\n",
       "315   [0.10676000798359503, 0.1352265550199152, 0.16...   \n",
       "1418  [0.23636279075585565, 0.18462696408895643, 0.1...   \n",
       "1586  [0.07166008142740465, 0.047778338503419115, 0....   \n",
       "1304  [-0.009835293598469075, 0.0020547030896352, 0....   \n",
       "1403  [0.06612189992800424, 0.04223707175027987, 0.0...   \n",
       "...                                                 ...   \n",
       "19    [0.005163662803639113, -0.007902433662855389, ...   \n",
       "659   [0.0749673832424401, 0.11344816950968292, 0.11...   \n",
       "1172  [0.048754791781123276, -0.010532678310044431, ...   \n",
       "592   [0.02340644303417705, -0.02244674771279879, -0...   \n",
       "653   [0.14691123434225106, 0.14335331038382687, 0.1...   \n",
       "\n",
       "                                                     15  \\\n",
       "315   [0.06702976130612603, 0.0954466221085365, 0.08...   \n",
       "1418  [0.03444901493473503, -0.02363062946580162, 0....   \n",
       "1586  [0.1227195878695772, 0.07365038036091497, 0.13...   \n",
       "1304  [0.08295863568262693, 0.07835182580882857, 0.0...   \n",
       "1403  [0.03978380724018162, 0.03082718348579546, 0.0...   \n",
       "...                                                 ...   \n",
       "19    [0.1975184775142403, 0.18187000759027766, 0.13...   \n",
       "659   [0.06575425986546093, 0.008815140896914398, 0....   \n",
       "1172  [-0.009389868114192564, 0.05626463123626152, -...   \n",
       "592   [0.06958524365995945, 0.07448553631232019, 0.0...   \n",
       "653   [0.020000371252096437, 0.015554615316314246, 0...   \n",
       "\n",
       "                                                     16  \\\n",
       "315   [0.10614167247593251, 0.07291824368302306, 0.0...   \n",
       "1418  [0.0010415763325745328, -0.001213159599028752,...   \n",
       "1586  [0.031719475578899536, 0.05184732744391414, -0...   \n",
       "1304  [0.11666549997208643, 0.1483304373672984, 0.15...   \n",
       "1403  [0.06702289153132387, 0.08597097986134394, 0.0...   \n",
       "...                                                 ...   \n",
       "19    [0.03965852338819514, 0.03847887551587167, 0.0...   \n",
       "659   [0.15691693161289388, 0.12343233818398494, 0.1...   \n",
       "1172  [0.026839350527689654, 0.03126140783026943, 0....   \n",
       "592   [0.03388775903802498, 0.06887939181420141, 0.0...   \n",
       "653   [0.03549430492814642, 0.04634538387306506, -0....   \n",
       "\n",
       "                                                     17  \\\n",
       "315   [0.061992768222163874, 0.05333033446091844, 0....   \n",
       "1418  [0.011730557912886238, 0.04428525576725784, 0....   \n",
       "1586  [0.17889951272079263, 0.2003681779675323, 0.20...   \n",
       "1304  [0.011511348004738547, 0.0019885710634519396, ...   \n",
       "1403  [0.12614030653994351, 0.12605561923176406, 0.1...   \n",
       "...                                                 ...   \n",
       "19    [0.1438234561847188, 0.10453966171712024, 0.14...   \n",
       "659   [0.005280289497362639, 0.04404464191903978, 0....   \n",
       "1172  [0.0693982227406164, 0.034726979958988186, 0.0...   \n",
       "592   [-0.002023080393315304, 0.03167344931961571, -...   \n",
       "653   [0.053428776541316045, 0.03317379010214638, 0....   \n",
       "\n",
       "                                                     18  \\\n",
       "315   [0.09182678788742905, 0.08682577657065811, 0.0...   \n",
       "1418  [-0.0071883945090362895, 0.045028241497329397,...   \n",
       "1586  [0.09301336645181826, 0.09264389061209766, 0.1...   \n",
       "1304  [-0.009203023971486323, 0.049320054094552854, ...   \n",
       "1403  [0.13915350456031123, 0.0821819543346081, 0.15...   \n",
       "...                                                 ...   \n",
       "19    [0.030962552476900246, 0.031069376147055544, 0...   \n",
       "659   [0.06312590894646136, 0.06266121777444324, 0.0...   \n",
       "1172  [0.04819278460123301, 0.07106711834354168, 0.0...   \n",
       "592   [0.07084763160393513, 0.05575328993518228, 0.0...   \n",
       "653   [0.14241755689762844, 0.07511459318944892, 0.1...   \n",
       "\n",
       "                                                     19  \n",
       "315   [0.13398475225360676, 0.08897964417495526, 0.0...  \n",
       "1418  [0.15097594176868176, 0.16359982051452993, 0.1...  \n",
       "1586  [0.12163181568864329, 0.11755752035043009, 0.0...  \n",
       "1304  [-0.013720402705653709, 0.010060120869738592, ...  \n",
       "1403  [0.13554818644886246, 0.13063503342271954, 0.1...  \n",
       "...                                                 ...  \n",
       "19    [0.050657742496200704, -0.0258879786932455, -0...  \n",
       "659   [0.06965787767874532, 0.05984104508522715, 0.0...  \n",
       "1172  [0.06793961065522333, 0.061068797322317944, -0...  \n",
       "592   [0.045310632263221816, 0.03262440132974497, 0....  \n",
       "653   [0.022331081815912233, 0.05484102672682166, 0....  \n",
       "\n",
       "[1280 rows x 20 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "189f5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/users/mgolovan/data/mgolovan/simulation_data_vectors/\"\n",
    "\n",
    "for i in range(20):\n",
    "    train_inputs = TensorDataset(torch.Tensor(np.array(list(X_train[i].values))), torch.Tensor(y_train.astype(int).values))\n",
    "    val_inputs = TensorDataset(torch.Tensor(np.array(list(X_val[i].values))), torch.Tensor(y_val.astype(int).values))\n",
    "    test_inputs = TensorDataset(torch.Tensor(np.array(list(X_test[i].values))), torch.Tensor(y_test.astype(int).values))\n",
    "\n",
    "    torch.save(train_inputs, path + \"train_modality_\" + str(i) +  \"_inputs.pt\")\n",
    "    torch.save(val_inputs, path + \"val_modality_\" + str(i) +  \"_inputs.pt\")\n",
    "    torch.save(test_inputs, path + \"test_modality_\" + str(i) +  \"_inputs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "98c3b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"/users/mgolovan/data/mgolovan/simulation_data_vectors/X_train.pkl\")\n",
    "y_train.to_pickle(\"/users/mgolovan/data/mgolovan/simulation_data_vectors/y_train.pkl\")\n",
    "X_test.to_pickle(\"/users/mgolovan/data/mgolovan/simulation_data_vectors/X_test.pkl\")\n",
    "y_test.to_pickle(\"/users/mgolovan/data/mgolovan/simulation_data_vectors/y_test.pkl\")\n",
    "X_val.to_pickle(\"/users/mgolovan/data/mgolovan/simulation_data_vectors/X_val.pkl\")\n",
    "y_val.to_pickle(\"/users/mgolovan/data/mgolovan/simulation_data_vectors/y_val.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814d279",
   "metadata": {},
   "source": [
    "X_train = pd.read_csv(\"simulation_data/X_train.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "y_train = pd.read_csv(\"simulation_data/y_train.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "X_test = pd.read_csv(\"simulation_data/X_test.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "y_test = pd.read_csv(\"simulation_data/y_test.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "X_val = pd.read_csv(\"simulation_data/X_val.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "y_val = pd.read_csv(\"simulation_data/y_val.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65f1bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efe9ef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, D_in, H, D_out=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(D_in, H)\n",
    "        self.fc2 = nn.Linear(5120, D_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "\n",
    "        return x #.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c98f87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in, H = 20, 256\n",
    "\n",
    "model = Net(D_in, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "150e8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84ee83e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.3274 Acc: 0.8469\n",
      "val Loss: 0.0853 Acc: 0.9844\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0700 Acc: 0.9836\n",
      "val Loss: 0.0472 Acc: 0.9875\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0604 Acc: 0.9812\n",
      "val Loss: 0.0356 Acc: 0.9938\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0965 Acc: 0.9719\n",
      "val Loss: 0.0368 Acc: 0.9875\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.1145 Acc: 0.9609\n",
      "val Loss: 0.0358 Acc: 0.9906\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0376 Acc: 0.9914\n",
      "val Loss: 0.0229 Acc: 0.9906\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0583 Acc: 0.9836\n",
      "val Loss: 0.0446 Acc: 0.9875\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0418 Acc: 0.9883\n",
      "val Loss: 0.0894 Acc: 0.9625\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1014 Acc: 0.9672\n",
      "val Loss: 0.0522 Acc: 0.9781\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0446 Acc: 0.9859\n",
      "val Loss: 0.0444 Acc: 0.9875\n",
      "Training complete in 3m 33s\n",
      "Best val Acc: 0.993750\n"
     ]
    }
   ],
   "source": [
    "#from model_utils import set_seed\n",
    "import time\n",
    "trainset = TensorDataset(torch.Tensor(X_train[np.array(range(0,20))].values.tolist()), torch.Tensor(y_train.values))\n",
    "valset = TensorDataset(torch.Tensor(X_val[np.array(range(0,20))].values.tolist()), torch.Tensor(y_val.values))\n",
    "testset = TensorDataset(torch.Tensor(X_test[np.array(range(0,20))].values.tolist()), torch.Tensor(y_test.values))\n",
    "\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=16, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=16, shuffle=False)\n",
    "\n",
    "dataloaders = {'train':trainloader, 'val':valloader}\n",
    "\n",
    "#set_seed(42)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "val_acc_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "\n",
    "best_acc = 0.0\n",
    "patience = 5 \n",
    "trigger = 0\n",
    "acc_dict = {}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #scheduler.step()\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        predicted_labels, ground_truth_labels = [], []\n",
    "        \n",
    "        \n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                loss = criterion(outputs, labels.squeeze().long())\n",
    "\n",
    "                \n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            #print(\"text_inp.size(0)\")\n",
    "            #print(text_inp.size(0))\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.squeeze())\n",
    "            predicted_labels.extend(preds.cpu().detach().numpy())\n",
    "            ground_truth_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        if phase == 'val':\n",
    "            acc_dict[epoch] = float(epoch_acc.detach().cpu())\n",
    "            val_acc_history.append(epoch_acc)\n",
    "            val_loss_history.append(epoch_loss)\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "\n",
    "        if phase == 'train':\n",
    "\n",
    "            train_acc_history.append(epoch_acc.detach().cpu())\n",
    "            train_loss_history.append(epoch_loss)\n",
    "\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "#model.load_state_dict(best_model_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f8d5f0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6fa6b55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e88bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(torch.Tensor(X_test[np.array(range(0,20))].values.tolist()))\n",
    "_, preds = torch.max(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d0d9122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(preds) == y_test.values).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6e39599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "# import pandas_path  # Path style access for pandas\n",
    "from tqdm import tqdm\n",
    "import torch                    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch import flatten\n",
    "\n",
    "from collections import OrderedDict\n",
    "from transformers import BertModel, DistilBertModel\n",
    "\n",
    "from PIL import ImageFile,Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from itertools import combinations\n",
    "  \n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, encoder_dim: int, decoder_dim: int):\n",
    "        super().__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "\n",
    "    def forward(self, \n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
    "        ):\n",
    "        weights = self._get_weights(query, values) # [seq_length]\n",
    "        weights = torch.nn.functional.softmax(weights, dim=0)\n",
    "        return weights @ values  # [encoder_dim]\n",
    "\n",
    "\n",
    "class OneVSOthers(Attention):\n",
    "\n",
    "    def __init__(self, encoder_dim: int, decoder_dim: int):\n",
    "        super().__init__(encoder_dim, decoder_dim)\n",
    "        self.W = torch.nn.Parameter(torch.FloatTensor(self.decoder_dim, self.encoder_dim).uniform_(-0.1, 0.1)) #.to('cuda')\n",
    "\n",
    "    def _get_weights(self,others, main):\n",
    "        mean = sum(others) / len(others)\n",
    "        weights = mean @ self.W @ main.T  # [seq_length]\n",
    "        return weights  \n",
    "\n",
    "class concat(nn.Module):\n",
    "\n",
    "    def __init__(self,num_mod):\n",
    "        super().__init__()\n",
    "        self.num_mod = num_mod\n",
    "        \n",
    "        \n",
    "        #input layers\n",
    "        #input layers\n",
    "        self.fc1 = nn.Linear(20, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fc1_layers = nn.ModuleList()\n",
    "        self.fc2_layers = nn.ModuleList()\n",
    "        for i in range(self.num_mod):\n",
    "            self.fc1_layers.append(nn.Linear(self.modality_dims[i], 256))\n",
    "            self.fc2_layers.append(nn.Linear(256*self.modality_dims[i], 256))\n",
    "        \n",
    "        \"\"\"\n",
    "        ##MLP\n",
    "        #self.fc2b = nn.Linear(256, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #out\n",
    "        self.out_concat = nn.Linear(256*self.num_mod, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x is a list of inputs\n",
    "        outputs = []\n",
    "        for i in range(self.num_mod):\n",
    "            t = x[i]\n",
    "            t = self.fc1(t.to(torch.float32))\n",
    "            #t = torch.flatten(t, start_dim=1)\n",
    "            t = self.fc2(t)\n",
    "            t = self.relu(t)\n",
    "            outputs.append(t)\n",
    "\n",
    "        combined = torch.cat(outputs, dim=1)\n",
    "        out = self.out_concat(combined)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class vaswani(nn.Module):\n",
    "\n",
    "    def __init__(self, num_mod):\n",
    "        super().__init__()\n",
    "        self.num_mod = num_mod\n",
    "        \n",
    "        #input layers\n",
    "        self.fc1 = nn.Linear(20, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fc1_layers = nn.ModuleList()\n",
    "        self.fc2_layers = nn.ModuleList()\n",
    "        for i in range(self.num_mod):\n",
    "            self.fc1_layers.append(nn.Linear(self.modality_dims[i], 256))\n",
    "            self.fc2_layers.append(nn.Linear(256*self.modality_dims[i], 256))\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ##MLP\n",
    "        #self.fc2b = nn.Linear(256, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #attention\n",
    "        self.vaswani_attention  = nn.MultiheadAttention(256, 1, batch_first = True)\n",
    "        \n",
    "        #out\n",
    "        self.out_vaswani = nn.Linear(256*self.num_mod*(self.num_mod-1), 2)\n",
    "        \n",
    "        \n",
    "    def bi_directional_att(self, l):\n",
    "\n",
    "        # All possible pairs in List\n",
    "        # Using combinations()\n",
    "        a = list(range(len(l)))\n",
    "        pairs = list(combinations(a, r=2))\n",
    "        #pairs = torch.combinations(torch.tensor(l), 2)\n",
    "        combos = []\n",
    "        for pair in pairs:\n",
    "            #(0,1)\n",
    "            index_1 = pair[0]\n",
    "            index_2 = pair[1]\n",
    "            x = l[index_1]\n",
    "            y = l[index_2]\n",
    "            attn_output_LV, attn_output_weights_LV = self.vaswani_attention(x, y, y)\n",
    "            attn_output_VL, attn_output_weights_VL = self.vaswani_attention(y, x, x)\n",
    "            combined = torch.cat((attn_output_LV,\n",
    "                                  attn_output_VL), dim=1)\n",
    "            combos.append(combined)\n",
    "        return combos\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x is a list of inputs\n",
    "        outputs = []\n",
    "        for i in range(self.num_mod):\n",
    "            t = x[i]\n",
    "            t = self.fc1(t.to(torch.float32))\n",
    "            #t = torch.flatten(t, start_dim=1)\n",
    "            t = self.fc2(t)\n",
    "            t = self.relu(t)\n",
    "            outputs.append(t)\n",
    "\n",
    "        combined = self.bi_directional_att(outputs)\n",
    "        comb = torch.cat(combined, dim=1)\n",
    "        out = self.out_vaswani(comb)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class OvO(nn.Module):\n",
    "\n",
    "    def __init__(self, num_mod):\n",
    "        super().__init__()\n",
    "        self.num_mod = num_mod\n",
    "        \n",
    "        #input layers\n",
    "        self.fc1 = nn.Linear(20, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fc1_layers = nn.ModuleList()\n",
    "        self.fc2_layers = nn.ModuleList()\n",
    "        for i in range(self.num_mod):\n",
    "            self.fc1_layers.append(nn.Linear(self.modality_dims[i], 256))\n",
    "            self.fc2_layers.append(nn.Linear(256*self.modality_dims[i], 256))\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ##MLP\n",
    "        self.fc2b = nn.Linear(256, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #attention\n",
    "        self.OvO_attention = OneVSOthers(encoder_dim=256, decoder_dim=256)\n",
    "        \n",
    "        #out\n",
    "        self.out_OvO = nn.Linear(256*self.num_mod, 2)\n",
    "     \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x is a list of inputs\n",
    "        outputs = []\n",
    "        for i in range(self.num_mod):\n",
    "            t = x[i]\n",
    "            t = self.fc1(t.to(torch.float32))\n",
    "            #t = torch.flatten(t, start_dim=1)\n",
    "            t = self.fc2(t)\n",
    "            t = self.relu(t)\n",
    "            outputs.append(t)\n",
    "\n",
    "\n",
    "        attns = []\n",
    "        for main in outputs:\n",
    "            others = list(set(outputs) - set([main]))\n",
    "            att = self.OvO_attention(others, main)\n",
    "            attns.append(att)\n",
    "        comb = torch.cat(attns, dim=1)\n",
    "        out = self.out_OvO(comb)\n",
    "\n",
    "        return out\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5084de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, dataloaders, criterion, len_train, len_val, path, num_mod, num_heads):\n",
    "    \n",
    "    set_seed(42)\n",
    "    if model_name == \"concat\":\n",
    "        model = concat(num_mod)\n",
    "    elif model_name == \"vaswani\":\n",
    "        model = vaswani(num_mod, num_heads)\n",
    "    else:\n",
    "        model = OvO(num_mod, num_heads)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    num_epochs = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "    \n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    patience = 10 \n",
    "    trigger = 0\n",
    "    acc_dict = {}\n",
    "    for epoch in range(num_epochs):\n",
    "        #scheduler.step()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                length = len_train\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                length = len_val\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                #print(data)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    mod1 = data[0]\n",
    "                    \n",
    "                    inp1, labels = mod1\n",
    "                    inp1, labels = inp1.to(device), labels.to(device)\n",
    "                    inps = []\n",
    "                    for i in range(len(data)):\n",
    "                        inp, labels = data[i]\n",
    "                        inp, labels = inp.to(device), labels.to(device)\n",
    "                        inps.append(inp)\n",
    "\n",
    "                    inp_len = labels.size(0)\n",
    "                    outputs = model(inps) #, model_name\n",
    "                    loss = criterion(outputs, labels.squeeze().long())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "             \n",
    "                running_loss += loss.item() * inp_len\n",
    "                running_corrects += torch.sum(preds == labels.squeeze())\n",
    "\n",
    "            epoch_loss = running_loss / length\n",
    "            epoch_acc = running_corrects.double() / length\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val':\n",
    "                #wandb.log({\"val_loss\": epoch_loss, \"val_acc\": epoch_acc})\n",
    "                acc_dict[epoch] = float(epoch_acc.detach().cpu())\n",
    "                val_acc_history.append(epoch_acc.detach().cpu())\n",
    "                val_loss_history.append(epoch_loss) \n",
    "                #torch.save(model.state_dict(), path+\"_current.pth\")\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    #best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    #torch.save(model.state_dict(), path+\"_best.pth\")\n",
    "                \"\"\"    \n",
    "                if (epoch > 10) and (acc_dict[epoch] <= acc_dict[epoch - 10]):\n",
    "                    trigger +=1\n",
    "                    if trigger >= patience:\n",
    "                        print('Best val Acc: {:4f}'.format(best_acc))\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        return model, {\"train_acc\":train_acc_history, \"val_acc\":val_acc_history,\"train_loss\":train_loss_history, \"val_loss\":val_loss_history}\n",
    "                else:\n",
    "                    trigger = 0\n",
    "                \"\"\"   \n",
    "            if phase == 'train':\n",
    "                #wandb.log({\"train_loss\": epoch_loss, \"train_acc\": epoch_acc, \"epoch\": epoch})\n",
    "                train_acc_history.append(epoch_acc.detach().cpu())\n",
    "                train_loss_history.append(epoch_loss)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, {\"train_acc\":train_acc_history, \"val_acc\":val_acc_history,\"train_loss\":train_loss_history, \"val_loss\":val_loss_history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b02692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    test_labels = []\n",
    "\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            mod1 = data[0]                    \n",
    "            inp1, labels = mod1\n",
    "            inp1, labels = inp1.to(device), labels.to(device)\n",
    "            inps = []\n",
    "            for i in range(len(data)):\n",
    "                inp, labels = data[i]\n",
    "                inp, labels = inp.to(device), labels.to(device)\n",
    "                inps.append(inp)\n",
    "\n",
    "            inp_len = labels.size(0)\n",
    "            outputs = model(inps) #, model_name\n",
    "            \n",
    "            test_labels.extend(np.array(labels.cpu()))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            pred.extend(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc= 100 * correct / total\n",
    "    print(f'Accuracy: {100 * correct / total} %')\n",
    "    return acc\n",
    "    #test_labels = np.array(test_labels)\n",
    "    #cm = confusion_matrix(test_labels, pred)\n",
    "    #print(f'F1-score: {cr[\"macro avg\"][\"f1-score\"]*100} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffb2eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/ceickhof/mgolovan/test-yang-py3.7/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "def calc_flops(model):\n",
    "    inputs = torch.tensor(X_test[np.array(range(0,i+1))].reset_index(drop=True).loc[0].values.tolist()).unsqueeze(1)\n",
    "    flops = FlopCountAnalysis(model, inputs)\n",
    "    return flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3146ce7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_modalities</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>FLOPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [num_modalities, model_name, test_accuracy, FLOPS]\n",
       "Index: []"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\"num_modalities\", \"model_name\", \"test_accuracy\", \"FLOPS\"]) #\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69bd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import random\n",
    "# import pandas_path  # Path style access for pandas\n",
    "from tqdm import tqdm\n",
    "import torch                    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch import flatten\n",
    "\n",
    "from collections import OrderedDict\n",
    "from transformers import BertModel, DistilBertModel\n",
    "\n",
    "from PIL import ImageFile,Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from itertools import combinations\n",
    "  \n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, encoder_dim: int, decoder_dim: int):\n",
    "        super().__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "\n",
    "    def forward(self, \n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
    "        ):\n",
    "        weights = self._get_weights(query, values) # [seq_length]\n",
    "        weights = torch.nn.functional.softmax(weights, dim=0)\n",
    "        return weights @ values  # [encoder_dim]\n",
    "\n",
    "\n",
    "class OneVSOthers(Attention):\n",
    "\n",
    "    def __init__(self, encoder_dim: int, decoder_dim: int):\n",
    "        super().__init__(encoder_dim, decoder_dim)\n",
    "        self.W = torch.nn.Parameter(torch.FloatTensor(self.decoder_dim, self.encoder_dim).uniform_(-0.1, 0.1)) #.to('cuda')\n",
    "\n",
    "    def _get_weights(self,others, main):\n",
    "        mean = sum(others) / len(others)\n",
    "        weights = mean @ self.W @ main.T  # [seq_length]\n",
    "        return weights  \n",
    "\n",
    "class OvOAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OvOAttention, self).__init__()\n",
    "    \n",
    "    def forward(self, others, main, W):\n",
    "        mean = sum(others) / len(others)\n",
    "        score = mean.squeeze(2) @ W @ main.squeeze(2).transpose(1, 2) #.T\n",
    "        attn = F.softmax(score, -1)\n",
    "        context = torch.bmm(attn, main.squeeze(2))\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model: int = 512, num_heads: int = 8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model % num_heads should be zero.\"\n",
    "\n",
    "        self.d_head = int(d_model / num_heads)\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.ovo_attn = OvOAttention()\n",
    "        self.query_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "        self.key_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "        self.value_proj = nn.Linear(d_model, self.d_head * num_heads)\n",
    "        self.W = torch.nn.Parameter(torch.FloatTensor(self.d_head, self.d_head).uniform_(-0.1, 0.1))\n",
    "\n",
    "    def forward(self, other, main):\n",
    "        batch_size = main.size(0)\n",
    "        main = main.unsqueeze(1)\n",
    "        #tgt_len, bsz, embed_dim = main.shape\n",
    "        bsz, tgt_len, embed_dim = main.shape\n",
    "        src_len, _, _ = main.shape\n",
    "        \n",
    "        main = main.contiguous().view(tgt_len, bsz * self.num_heads, self.d_head).transpose(0, 1)\n",
    "        main = main.view(bsz, self.num_heads, tgt_len, self.d_head)\n",
    "        others = []\n",
    "        for mod in other:\n",
    "            mod = mod.unsqueeze(1)\n",
    "            mod = mod.contiguous().view(tgt_len, bsz * self.num_heads, self.d_head).transpose(0, 1)\n",
    "            mod = mod.view(bsz, self.num_heads, tgt_len, self.d_head)\n",
    "            others.append(mod)  \n",
    "        context, attn = self.ovo_attn(others, main, self.W)\n",
    "        context = context.contiguous().view(bsz * tgt_len, embed_dim)\n",
    "        context = context.view(bsz, tgt_len,  context.size(1))\n",
    "        \n",
    "        return context\n",
    "\n",
    "\n",
    "class concat(nn.Module):\n",
    "\n",
    "    def __init__(self,num_mod):\n",
    "        super().__init__()\n",
    "        self.num_mod = num_mod\n",
    "        \n",
    "        \n",
    "        #input layers\n",
    "        #input layers\n",
    "        self.fc1 = nn.Linear(20, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fc1_layers = nn.ModuleList()\n",
    "        self.fc2_layers = nn.ModuleList()\n",
    "        for i in range(self.num_mod):\n",
    "            self.fc1_layers.append(nn.Linear(self.modality_dims[i], 256))\n",
    "            self.fc2_layers.append(nn.Linear(256*self.modality_dims[i], 256))\n",
    "        \n",
    "        \"\"\"\n",
    "        ##MLP\n",
    "        #self.fc2b = nn.Linear(256, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #out\n",
    "        self.out_concat = nn.Linear(256*self.num_mod, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x is a list of inputs\n",
    "        outputs = []\n",
    "        for i in range(self.num_mod):\n",
    "            t = x[i]\n",
    "            t = self.fc1(t.to(torch.float32))\n",
    "            #t = torch.flatten(t, start_dim=1)\n",
    "            t = self.fc2(t)\n",
    "            t = self.relu(t)\n",
    "            outputs.append(t)\n",
    "\n",
    "        combined = torch.cat(outputs, dim=1)\n",
    "        out = self.out_concat(combined)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class vaswani(nn.Module):\n",
    "\n",
    "    def __init__(self, num_mod, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_mod = num_mod\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        #input layers\n",
    "        self.fc1 = nn.Linear(20, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fc1_layers = nn.ModuleList()\n",
    "        self.fc2_layers = nn.ModuleList()\n",
    "        for i in range(self.num_mod):\n",
    "            self.fc1_layers.append(nn.Linear(self.modality_dims[i], 256))\n",
    "            self.fc2_layers.append(nn.Linear(256*self.modality_dims[i], 256))\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ##MLP\n",
    "        #self.fc2b = nn.Linear(256, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #attention\n",
    "        self.vaswani_attention  = nn.MultiheadAttention(256, self.num_heads, batch_first = True)\n",
    "        \n",
    "        #out\n",
    "        self.out_vaswani = nn.Linear(256*self.num_mod*(self.num_mod-1), 2)\n",
    "        \n",
    "        \n",
    "    def bi_directional_att(self, l):\n",
    "\n",
    "        # All possible pairs in List\n",
    "        # Using combinations()\n",
    "        a = list(range(len(l)))\n",
    "        pairs = list(combinations(a, r=2))\n",
    "        #pairs = torch.combinations(torch.tensor(l), 2)\n",
    "        combos = []\n",
    "        for pair in pairs:\n",
    "            #(0,1)\n",
    "            index_1 = pair[0]\n",
    "            index_2 = pair[1]\n",
    "            x = l[index_1]\n",
    "            y = l[index_2]\n",
    "            attn_output_LV, attn_output_weights_LV = self.vaswani_attention(x, y, y)\n",
    "            attn_output_VL, attn_output_weights_VL = self.vaswani_attention(y, x, x)\n",
    "            combined = torch.cat((attn_output_LV,\n",
    "                                  attn_output_VL), dim=1)\n",
    "            combos.append(combined)\n",
    "        return combos\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x is a list of inputs\n",
    "        outputs = []\n",
    "        for i in range(self.num_mod):\n",
    "            t = x[i]\n",
    "            t = self.fc1(t.to(torch.float32))\n",
    "            #t = torch.flatten(t, start_dim=1)\n",
    "            t = self.fc2(t)\n",
    "            t = self.relu(t)\n",
    "            outputs.append(t)\n",
    "\n",
    "        combined = self.bi_directional_att(outputs)\n",
    "        comb = torch.cat(combined, dim=1)\n",
    "        out = self.out_vaswani(comb)\n",
    "        return out\n",
    "    \n",
    "class OvO(nn.Module):\n",
    "\n",
    "    def __init__(self, num_mod, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_mod = num_mod\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        #input layers\n",
    "        self.fc1 = nn.Linear(20, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fc1_layers = nn.ModuleList()\n",
    "        self.fc2_layers = nn.ModuleList()\n",
    "        for i in range(self.num_mod):\n",
    "            self.fc1_layers.append(nn.Linear(self.modality_dims[i], 256))\n",
    "            self.fc2_layers.append(nn.Linear(256*self.modality_dims[i], 256))\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ##MLP\n",
    "        self.fc2b = nn.Linear(256, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #attention\n",
    "        #self.OvO_attention = OneVSOthers(encoder_dim=256, decoder_dim=256)\n",
    "        self.OvO_multihead_attention = MultiHeadAttention(256,self.num_heads)\n",
    "        \n",
    "        #out\n",
    "        self.out_OvO = nn.Linear(256*self.num_mod, 2)\n",
    "     \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x is a list of inputs\n",
    "        outputs = []\n",
    "        for i in range(self.num_mod):\n",
    "            t = x[i]\n",
    "            t = self.fc1(t.to(torch.float32))\n",
    "            #t = torch.flatten(t, start_dim=1)\n",
    "            t = self.fc2(t)\n",
    "            t = self.relu(t)\n",
    "            outputs.append(t)\n",
    "\n",
    "\n",
    "        attns = []\n",
    "        for main in outputs:\n",
    "            others = list(set(outputs) - set([main]))\n",
    "            att = self.OvO_multihead_attention(others, main)\n",
    "            attns.append(att.squeeze(1))\n",
    "        comb = torch.cat(attns, dim=1)\n",
    "        out = self.out_OvO(comb)\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85780b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n",
      "Epoch 0/0\n",
      "----------\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 6 time(s)\n",
      "Unsupported operator aten::add encountered 2 time(s)\n",
      "Unsupported operator aten::div encountered 2 time(s)\n",
      "Unsupported operator aten::softmax encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "OvO_multihead_attention.key_proj, OvO_multihead_attention.query_proj, OvO_multihead_attention.value_proj, fc2b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "train Loss: 94.9579 Acc: 0.5133\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "val Loss: 132.8829 Acc: 0.4000\n",
      "Training complete in 0m 0s\n",
      "Best val Acc: 0.400000\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "torch.Size([16, 2])\n",
      "Accuracy: 36.5 %\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "from model_utils import MyLoader, set_seed\n",
    "#from models import MultimodalFramework\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "#from models import concat, vaswani, OvO\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "path_to_data = \"/users/mgolovan/data/mgolovan/simulation_data_vectors/\"\n",
    "X_test = pd.read_pickle(path_to_data+\"X_test.pkl\")\n",
    "y_test = pd.read_pickle(path_to_data+\"y_test.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(path_to_data+\"y_train.pkl\")\n",
    "y_val = pd.read_pickle(path_to_data+\"y_val.pkl\")\n",
    "\n",
    "num_modalities = 2\n",
    "\n",
    "#for model_name in [\"vaswani\"]: #\"vaswani\",\n",
    "model_name = \"OvO\"\n",
    "for i in range(1,num_modalities):\n",
    "    train_input_list = []\n",
    "    test_input_list = []\n",
    "    val_input_list = []\n",
    "\n",
    "    for j in range(i+1):\n",
    "        train_inputs = torch.load(path_to_data + \"train_modality_\" + str(j) +  \"_inputs.pt\")\n",
    "        val_inputs = torch.load(path_to_data + \"val_modality_\" + str(j) +  \"_inputs.pt\")\n",
    "        test_inputs = torch.load(path_to_data + \"test_modality_\" + str(j) +  \"_inputs.pt\")\n",
    "        train_input_list.append(DataLoader(train_inputs, batch_size=16,shuffle=False))\n",
    "        val_input_list.append(DataLoader(val_inputs, batch_size=16, shuffle=False))\n",
    "        test_input_list.append(DataLoader(test_inputs, batch_size=16, shuffle=False))\n",
    "        \n",
    "    train_loader = MyLoader(train_input_list)\n",
    "    val_loader = MyLoader(val_input_list)\n",
    "    test_loader = MyLoader(test_input_list)\n",
    "    dataloaders_dict = {'train':train_loader, 'val':val_loader}\n",
    "    len_val = len(y_val)\n",
    "    len_train = len(y_train)\n",
    "    path_to_model = 'model_' + str(i) + \"_\" + model_name \n",
    "    model, dic = train_model(model_name, dataloaders_dict, criterion, len_train, len_val, path_to_model, i+1, num_heads=4)\n",
    "\n",
    "    acc = eval(model, test_loader)\n",
    "    flops = calc_flops(model)\n",
    "    #df = df.append({'num_modalities': i+1, \"model_name\": model_name,\n",
    "    #                \"test_accuracy\":acc, \"FLOPS\": flops}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3fbc1967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>[0.03141351940154583, -0.011044356462206417, -...</td>\n",
       "      <td>[0.06557069325916193, 0.032177842025611095, 0....</td>\n",
       "      <td>[0.08430310870317767, 0.06424324397659856, 0.1...</td>\n",
       "      <td>[0.005784865407589733, 0.014961386101977524, 0...</td>\n",
       "      <td>[0.08293798299402709, 0.0512793124497917, 0.04...</td>\n",
       "      <td>[0.12071689873250782, 0.09361969712417716, 0.1...</td>\n",
       "      <td>[-0.005321498414961566, 0.001079986505247408, ...</td>\n",
       "      <td>[0.012953826961618453, 0.00025050917393011586,...</td>\n",
       "      <td>[0.026599400832991615, 0.05595237295166659, 0....</td>\n",
       "      <td>[0.03889469035733799, 0.009324133203464615, -0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.02636066665125339, 0.07366375518118445, 0.0...</td>\n",
       "      <td>[0.05868179674992134, 0.035633105864856573, 0....</td>\n",
       "      <td>[0.08014303460720211, 0.029820880448521575, 0....</td>\n",
       "      <td>[0.05923256243732212, 0.07010265178662486, 0.0...</td>\n",
       "      <td>[0.07720104895997836, 0.0923298173051055, 0.06...</td>\n",
       "      <td>[0.10953594288452118, 0.1474177292428278, 0.12...</td>\n",
       "      <td>[0.04524485153716616, 0.06089447052066114, 0.0...</td>\n",
       "      <td>[0.032481373848488, 0.009201604422756207, 0.02...</td>\n",
       "      <td>[0.09238452718072016, 0.049265080133587144, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>[0.10629587501579411, 0.053982375567181926, 0....</td>\n",
       "      <td>[0.1380727520898182, 0.12107026597437183, 0.17...</td>\n",
       "      <td>[0.0026832752275036953, 0.017745612995596766, ...</td>\n",
       "      <td>[0.06257883222904212, 0.050652580411113805, 0....</td>\n",
       "      <td>[0.03216889820117615, 0.07149315253624411, 0.0...</td>\n",
       "      <td>[0.03653138730738364, 0.03078155217290642, 0.0...</td>\n",
       "      <td>[0.11504168014895083, 0.09979083163169977, 0.0...</td>\n",
       "      <td>[0.003210036553204648, -0.01840047496455324, -...</td>\n",
       "      <td>[0.09886209975885679, 0.09647399093049296, 0.0...</td>\n",
       "      <td>[0.06212325175723368, 0.1338779952545195, 0.06...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.01334744384735444, 0.06200645510184957, 0.0...</td>\n",
       "      <td>[-0.01705872551608989, 0.008210816781645345, 0...</td>\n",
       "      <td>[0.08633689661528213, 0.12400589763125092, 0.1...</td>\n",
       "      <td>[0.16467630354705798, 0.11092963165353184, 0.1...</td>\n",
       "      <td>[0.017443362970980782, 0.02550759333632542, 0....</td>\n",
       "      <td>[0.07455409916885397, 0.07900098684998028, 0.0...</td>\n",
       "      <td>[0.11225897350329125, 0.10373050190273793, 0.1...</td>\n",
       "      <td>[0.029629728719411774, -0.013500045378899013, ...</td>\n",
       "      <td>[0.015176873970044687, 0.060346476349715156, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>[0.046592311084449056, -0.0011666615515541767,...</td>\n",
       "      <td>[0.05529494823276903, 0.10640270376287103, 0.0...</td>\n",
       "      <td>[0.045010892126157595, 0.05304661734498258, 0....</td>\n",
       "      <td>[0.0946024904105379, 0.11274064693124307, 0.09...</td>\n",
       "      <td>[0.08849403239152862, 0.08709247988983917, 0.0...</td>\n",
       "      <td>[0.07717774642384002, 0.016034828351886028, 0....</td>\n",
       "      <td>[0.10265956083540863, 0.10596648475157106, 0.1...</td>\n",
       "      <td>[0.04484365669148715, 0.029850573933416672, 0....</td>\n",
       "      <td>[0.10303936303197461, 0.10582915648956154, 0.0...</td>\n",
       "      <td>[0.16257877243975766, 0.1842083460461648, 0.18...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.10966924095407002, 0.11128181186050445, 0.0...</td>\n",
       "      <td>[0.10950410175697853, 0.11292570853717471, 0.1...</td>\n",
       "      <td>[0.07562112819783842, 0.10903873288169735, 0.0...</td>\n",
       "      <td>[0.11132856656716986, 0.08505358373684033, 0.0...</td>\n",
       "      <td>[0.04926506668427322, 0.022807663158812132, -0...</td>\n",
       "      <td>[0.10046067979805748, 0.13282068534696745, 0.1...</td>\n",
       "      <td>[0.11368708991457253, 0.11081266849470546, 0.0...</td>\n",
       "      <td>[0.014987804657915937, 0.03270146883940894, -0...</td>\n",
       "      <td>[0.157887971021904, 0.17912513335017693, 0.122...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>[0.0899539643180965, 0.09275985558926333, 0.12...</td>\n",
       "      <td>[0.047309845394079314, 0.03709271763828595, 0....</td>\n",
       "      <td>[0.02957051745338733, -0.004290186452598165, 0...</td>\n",
       "      <td>[0.151968828111482, 0.10717612664672946, 0.133...</td>\n",
       "      <td>[0.0836250692224832, 0.07650553124364037, 0.12...</td>\n",
       "      <td>[0.025991452358188845, 0.014777590550604632, -...</td>\n",
       "      <td>[0.03697256115233213, 0.06618379774292885, 0.1...</td>\n",
       "      <td>[0.032657634095686595, 0.029894763369460026, 0...</td>\n",
       "      <td>[0.14789513212315503, 0.12150281666664728, 0.0...</td>\n",
       "      <td>[-0.00013580453213782664, -0.00050997351333200...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.15788749647799102, 0.14578245580334726, 0.1...</td>\n",
       "      <td>[0.13169664930808866, 0.09399615532051527, 0.1...</td>\n",
       "      <td>[0.05204856468212047, 0.008372487827550262, 0....</td>\n",
       "      <td>[0.1407963516870951, 0.10372904960644133, 0.11...</td>\n",
       "      <td>[0.044560926146349426, -0.02393393043588572, 0...</td>\n",
       "      <td>[0.07495577398365397, 0.13729779060866287, 0.1...</td>\n",
       "      <td>[0.058654183764857835, 0.0694786416642261, 0.0...</td>\n",
       "      <td>[0.14650353958656553, 0.0997859547177187, 0.12...</td>\n",
       "      <td>[0.014424178994388265, 0.08242415753466956, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>[0.1420757452012886, 0.15988111411615477, 0.13...</td>\n",
       "      <td>[0.03369215370061424, -0.0033846941572399855, ...</td>\n",
       "      <td>[0.11083920788407514, 0.060962655706948005, 0....</td>\n",
       "      <td>[0.13683393042238995, 0.13204135379154344, 0.1...</td>\n",
       "      <td>[0.12949947959377284, 0.16172506535082656, 0.1...</td>\n",
       "      <td>[0.04910799136279005, 0.08173619115913304, 0.0...</td>\n",
       "      <td>[0.048281341885691595, 0.031188224843875373, 0...</td>\n",
       "      <td>[0.08275356867617165, 0.051475026593479946, 0....</td>\n",
       "      <td>[0.030601532080954803, 0.0015216699608665459, ...</td>\n",
       "      <td>[0.14621792762354716, 0.13730709717844508, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.1347006492091942, 0.16706253301807883, 0.13...</td>\n",
       "      <td>[0.1230948622867249, 0.11872826144117227, 0.08...</td>\n",
       "      <td>[-0.02624838409533284, -0.02523102455967592, 0...</td>\n",
       "      <td>[-0.0029751329999919453, 0.0180230977957846, -...</td>\n",
       "      <td>[0.11257762551525538, 0.11870044723764345, 0.0...</td>\n",
       "      <td>[0.02624932882205603, 0.050241430081379705, 0....</td>\n",
       "      <td>[0.095899552759829, 0.06179642215587275, 0.119...</td>\n",
       "      <td>[0.08109304747905269, 0.07076704353168761, 0.1...</td>\n",
       "      <td>[0.17479168601362755, 0.15031915539486237, 0.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>[0.06261100641434786, 0.10268482526676369, 0.0...</td>\n",
       "      <td>[0.02200975392517105, 0.0635496863725743, 0.05...</td>\n",
       "      <td>[0.011616433963281887, 0.013734576286063685, 0...</td>\n",
       "      <td>[0.12668785433298813, 0.07548948205232482, 0.1...</td>\n",
       "      <td>[0.05389721943103834, 0.06263977554268485, 0.0...</td>\n",
       "      <td>[0.022892419521221202, 0.041688566376890605, 0...</td>\n",
       "      <td>[0.022971574949316276, 0.036664041482202744, 0...</td>\n",
       "      <td>[0.1323646147788199, 0.1043993944096645, 0.101...</td>\n",
       "      <td>[0.017656501734534997, 0.0028593686360501927, ...</td>\n",
       "      <td>[0.10762213290860398, 0.12760665427977877, 0.1...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.029270613900291086, 0.03208893185935524, 0....</td>\n",
       "      <td>[0.13490971592654924, 0.11088642045050949, 0.1...</td>\n",
       "      <td>[0.027382489936420683, 0.04707731082016241, -0...</td>\n",
       "      <td>[0.10981973821381089, 0.06134068301042721, 0.0...</td>\n",
       "      <td>[0.07022880139832703, 0.10843957005575885, 0.0...</td>\n",
       "      <td>[0.14970731685539074, 0.12419332074076707, 0.1...</td>\n",
       "      <td>[0.15025467336008427, 0.1316269461474537, 0.14...</td>\n",
       "      <td>[0.09530357084016824, 0.07021453226350081, 0.1...</td>\n",
       "      <td>[-0.0014050363675178791, 0.032602402850896224,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>[0.010546372918382035, 0.012981614656102237, -...</td>\n",
       "      <td>[-0.010417151156266454, 0.051668731508050215, ...</td>\n",
       "      <td>[0.03450431046985525, 0.03854082334507779, 0.0...</td>\n",
       "      <td>[0.05636379566010937, 0.02385214760126612, 0.0...</td>\n",
       "      <td>[0.1623511226645863, 0.12053272172176405, 0.16...</td>\n",
       "      <td>[0.10371548225332405, 0.11620725885420384, 0.0...</td>\n",
       "      <td>[0.03417174382507057, 0.03275045332956193, -0....</td>\n",
       "      <td>[0.11468183148410424, 0.10884265793813463, 0.0...</td>\n",
       "      <td>[0.03619141756816223, 0.035419347849264565, -0...</td>\n",
       "      <td>[-0.009654615671215512, 0.021423906054921428, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.007717981046955202, 0.01682810085689792, -0...</td>\n",
       "      <td>[0.08422019745863571, 0.013171206723039883, 0....</td>\n",
       "      <td>[0.050417243291934546, 0.02852431865926448, 0....</td>\n",
       "      <td>[0.04273405148331667, -0.024062048521073985, 0...</td>\n",
       "      <td>[0.03373844754273273, 0.043420998734551595, -0...</td>\n",
       "      <td>[0.09600130487921885, 0.18144763201027964, 0.1...</td>\n",
       "      <td>[0.04704052617442797, 0.09225077881264107, 0.0...</td>\n",
       "      <td>[0.029776917964145236, 0.05304564602257271, 0....</td>\n",
       "      <td>[0.0487987153769409, -0.0030118234032506866, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>[0.1149371227987954, 0.11679835406675088, 0.11...</td>\n",
       "      <td>[0.10115025026898777, 0.10997266411700761, 0.0...</td>\n",
       "      <td>[0.11216760582475402, 0.18519481250956812, 0.1...</td>\n",
       "      <td>[0.018795396937174885, 0.01567850767151218, -0...</td>\n",
       "      <td>[0.04757604963155352, 0.04089661182341163, 0.0...</td>\n",
       "      <td>[0.030284152957753684, 0.008054349055576143, 0...</td>\n",
       "      <td>[-0.015954967733301545, 0.004015537340914862, ...</td>\n",
       "      <td>[0.07240737158718483, 0.031524573649897435, 0....</td>\n",
       "      <td>[0.025587070428751937, 0.04954393726535852, 0....</td>\n",
       "      <td>[0.17405916612586075, 0.10375867622805807, 0.1...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.10970143396089793, 0.10710204116791225, 0.1...</td>\n",
       "      <td>[0.08858389997945097, 0.1354233513644226, 0.10...</td>\n",
       "      <td>[0.12202284305103817, 0.13220191033971584, 0.1...</td>\n",
       "      <td>[0.0977829139163811, 0.10178696275737856, 0.08...</td>\n",
       "      <td>[0.13772268559614928, 0.15322024795091804, 0.1...</td>\n",
       "      <td>[0.0027431957723392, 0.05789473897387325, 0.02...</td>\n",
       "      <td>[0.009301576010965967, 0.05809421714800441, 0....</td>\n",
       "      <td>[-0.001911665996093062, -0.029990861168359344,...</td>\n",
       "      <td>[0.1602293538247419, 0.09205182017563461, 0.17...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>[0.08348436362871947, 0.12032201569601583, 0.0...</td>\n",
       "      <td>[0.11838522161197321, 0.136411184710956, 0.124...</td>\n",
       "      <td>[0.09133140620012804, 0.10108486058314876, 0.1...</td>\n",
       "      <td>[0.16183195660786232, 0.13128541873525146, 0.1...</td>\n",
       "      <td>[0.14152056165685717, 0.14124131645395718, 0.1...</td>\n",
       "      <td>[0.10412551408413011, 0.10151776756431172, 0.1...</td>\n",
       "      <td>[0.08700741850495569, 0.1116089865562648, 0.06...</td>\n",
       "      <td>[0.01387299290485525, 0.03588912020775907, 0.0...</td>\n",
       "      <td>[0.1579177659962111, 0.1506932499860362, 0.182...</td>\n",
       "      <td>[0.011001620037581539, 0.07763397746068441, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.16037842533491392, 0.1413741347070024, 0.14...</td>\n",
       "      <td>[0.05460220213030381, 0.03304292023218894, 0.0...</td>\n",
       "      <td>[0.08458951247297508, 0.04247845191685122, 0.0...</td>\n",
       "      <td>[0.07275947630272714, 0.10598496755796272, 0.0...</td>\n",
       "      <td>[0.10002281475099782, 0.10033180198436606, 0.1...</td>\n",
       "      <td>[0.012537603011767512, -0.0019225448207104926,...</td>\n",
       "      <td>[0.10820382421948196, 0.062085552036107466, 0....</td>\n",
       "      <td>[0.0891020531206432, 0.0595883297504446, 0.036...</td>\n",
       "      <td>[0.04325029765388048, 0.03375257683415552, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>[0.10103862545166277, 0.12982685337086572, 0.0...</td>\n",
       "      <td>[0.12139558871163544, 0.10430690275678992, 0.1...</td>\n",
       "      <td>[0.158462424626707, 0.1269961828267089, 0.1739...</td>\n",
       "      <td>[0.12465862864310119, 0.09550738284138229, 0.1...</td>\n",
       "      <td>[0.010279720882161739, 0.039581557079548926, 0...</td>\n",
       "      <td>[0.1264376384468791, 0.11261218838602824, 0.05...</td>\n",
       "      <td>[0.06635349849664937, 0.06211711507439848, 0.0...</td>\n",
       "      <td>[0.046495591401213274, 0.06930270976151996, 0....</td>\n",
       "      <td>[0.11962444468324915, 0.15292738775326445, 0.1...</td>\n",
       "      <td>[0.09664849894042471, 0.08529115282139876, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.052767200036594644, 0.0855428795811954, 0.1...</td>\n",
       "      <td>[0.06900184442971712, 0.06003054383298033, 0.0...</td>\n",
       "      <td>[0.07095219484039206, 0.045180514372242186, 0....</td>\n",
       "      <td>[0.03545570732266198, -0.008890905482849189, -...</td>\n",
       "      <td>[0.03236722536027384, -0.00043939836772954183,...</td>\n",
       "      <td>[0.07183892844738476, 0.05939049776443401, 0.0...</td>\n",
       "      <td>[0.15182938120644857, 0.13661599740524183, 0.1...</td>\n",
       "      <td>[0.09621070734979889, 0.11255830109412886, 0.1...</td>\n",
       "      <td>[0.09001955572949016, 0.07754036079173593, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0  \\\n",
       "1860  [0.03141351940154583, -0.011044356462206417, -...   \n",
       "353   [0.10629587501579411, 0.053982375567181926, 0....   \n",
       "1333  [0.046592311084449056, -0.0011666615515541767,...   \n",
       "905   [0.0899539643180965, 0.09275985558926333, 0.12...   \n",
       "1289  [0.1420757452012886, 0.15988111411615477, 0.13...   \n",
       "...                                                 ...   \n",
       "965   [0.06261100641434786, 0.10268482526676369, 0.0...   \n",
       "1284  [0.010546372918382035, 0.012981614656102237, -...   \n",
       "1739  [0.1149371227987954, 0.11679835406675088, 0.11...   \n",
       "261   [0.08348436362871947, 0.12032201569601583, 0.0...   \n",
       "535   [0.10103862545166277, 0.12982685337086572, 0.0...   \n",
       "\n",
       "                                                      1  \\\n",
       "1860  [0.06557069325916193, 0.032177842025611095, 0....   \n",
       "353   [0.1380727520898182, 0.12107026597437183, 0.17...   \n",
       "1333  [0.05529494823276903, 0.10640270376287103, 0.0...   \n",
       "905   [0.047309845394079314, 0.03709271763828595, 0....   \n",
       "1289  [0.03369215370061424, -0.0033846941572399855, ...   \n",
       "...                                                 ...   \n",
       "965   [0.02200975392517105, 0.0635496863725743, 0.05...   \n",
       "1284  [-0.010417151156266454, 0.051668731508050215, ...   \n",
       "1739  [0.10115025026898777, 0.10997266411700761, 0.0...   \n",
       "261   [0.11838522161197321, 0.136411184710956, 0.124...   \n",
       "535   [0.12139558871163544, 0.10430690275678992, 0.1...   \n",
       "\n",
       "                                                      2  \\\n",
       "1860  [0.08430310870317767, 0.06424324397659856, 0.1...   \n",
       "353   [0.0026832752275036953, 0.017745612995596766, ...   \n",
       "1333  [0.045010892126157595, 0.05304661734498258, 0....   \n",
       "905   [0.02957051745338733, -0.004290186452598165, 0...   \n",
       "1289  [0.11083920788407514, 0.060962655706948005, 0....   \n",
       "...                                                 ...   \n",
       "965   [0.011616433963281887, 0.013734576286063685, 0...   \n",
       "1284  [0.03450431046985525, 0.03854082334507779, 0.0...   \n",
       "1739  [0.11216760582475402, 0.18519481250956812, 0.1...   \n",
       "261   [0.09133140620012804, 0.10108486058314876, 0.1...   \n",
       "535   [0.158462424626707, 0.1269961828267089, 0.1739...   \n",
       "\n",
       "                                                      3  \\\n",
       "1860  [0.005784865407589733, 0.014961386101977524, 0...   \n",
       "353   [0.06257883222904212, 0.050652580411113805, 0....   \n",
       "1333  [0.0946024904105379, 0.11274064693124307, 0.09...   \n",
       "905   [0.151968828111482, 0.10717612664672946, 0.133...   \n",
       "1289  [0.13683393042238995, 0.13204135379154344, 0.1...   \n",
       "...                                                 ...   \n",
       "965   [0.12668785433298813, 0.07548948205232482, 0.1...   \n",
       "1284  [0.05636379566010937, 0.02385214760126612, 0.0...   \n",
       "1739  [0.018795396937174885, 0.01567850767151218, -0...   \n",
       "261   [0.16183195660786232, 0.13128541873525146, 0.1...   \n",
       "535   [0.12465862864310119, 0.09550738284138229, 0.1...   \n",
       "\n",
       "                                                      4  \\\n",
       "1860  [0.08293798299402709, 0.0512793124497917, 0.04...   \n",
       "353   [0.03216889820117615, 0.07149315253624411, 0.0...   \n",
       "1333  [0.08849403239152862, 0.08709247988983917, 0.0...   \n",
       "905   [0.0836250692224832, 0.07650553124364037, 0.12...   \n",
       "1289  [0.12949947959377284, 0.16172506535082656, 0.1...   \n",
       "...                                                 ...   \n",
       "965   [0.05389721943103834, 0.06263977554268485, 0.0...   \n",
       "1284  [0.1623511226645863, 0.12053272172176405, 0.16...   \n",
       "1739  [0.04757604963155352, 0.04089661182341163, 0.0...   \n",
       "261   [0.14152056165685717, 0.14124131645395718, 0.1...   \n",
       "535   [0.010279720882161739, 0.039581557079548926, 0...   \n",
       "\n",
       "                                                      5  \\\n",
       "1860  [0.12071689873250782, 0.09361969712417716, 0.1...   \n",
       "353   [0.03653138730738364, 0.03078155217290642, 0.0...   \n",
       "1333  [0.07717774642384002, 0.016034828351886028, 0....   \n",
       "905   [0.025991452358188845, 0.014777590550604632, -...   \n",
       "1289  [0.04910799136279005, 0.08173619115913304, 0.0...   \n",
       "...                                                 ...   \n",
       "965   [0.022892419521221202, 0.041688566376890605, 0...   \n",
       "1284  [0.10371548225332405, 0.11620725885420384, 0.0...   \n",
       "1739  [0.030284152957753684, 0.008054349055576143, 0...   \n",
       "261   [0.10412551408413011, 0.10151776756431172, 0.1...   \n",
       "535   [0.1264376384468791, 0.11261218838602824, 0.05...   \n",
       "\n",
       "                                                      6  \\\n",
       "1860  [-0.005321498414961566, 0.001079986505247408, ...   \n",
       "353   [0.11504168014895083, 0.09979083163169977, 0.0...   \n",
       "1333  [0.10265956083540863, 0.10596648475157106, 0.1...   \n",
       "905   [0.03697256115233213, 0.06618379774292885, 0.1...   \n",
       "1289  [0.048281341885691595, 0.031188224843875373, 0...   \n",
       "...                                                 ...   \n",
       "965   [0.022971574949316276, 0.036664041482202744, 0...   \n",
       "1284  [0.03417174382507057, 0.03275045332956193, -0....   \n",
       "1739  [-0.015954967733301545, 0.004015537340914862, ...   \n",
       "261   [0.08700741850495569, 0.1116089865562648, 0.06...   \n",
       "535   [0.06635349849664937, 0.06211711507439848, 0.0...   \n",
       "\n",
       "                                                      7  \\\n",
       "1860  [0.012953826961618453, 0.00025050917393011586,...   \n",
       "353   [0.003210036553204648, -0.01840047496455324, -...   \n",
       "1333  [0.04484365669148715, 0.029850573933416672, 0....   \n",
       "905   [0.032657634095686595, 0.029894763369460026, 0...   \n",
       "1289  [0.08275356867617165, 0.051475026593479946, 0....   \n",
       "...                                                 ...   \n",
       "965   [0.1323646147788199, 0.1043993944096645, 0.101...   \n",
       "1284  [0.11468183148410424, 0.10884265793813463, 0.0...   \n",
       "1739  [0.07240737158718483, 0.031524573649897435, 0....   \n",
       "261   [0.01387299290485525, 0.03588912020775907, 0.0...   \n",
       "535   [0.046495591401213274, 0.06930270976151996, 0....   \n",
       "\n",
       "                                                      8  \\\n",
       "1860  [0.026599400832991615, 0.05595237295166659, 0....   \n",
       "353   [0.09886209975885679, 0.09647399093049296, 0.0...   \n",
       "1333  [0.10303936303197461, 0.10582915648956154, 0.0...   \n",
       "905   [0.14789513212315503, 0.12150281666664728, 0.0...   \n",
       "1289  [0.030601532080954803, 0.0015216699608665459, ...   \n",
       "...                                                 ...   \n",
       "965   [0.017656501734534997, 0.0028593686360501927, ...   \n",
       "1284  [0.03619141756816223, 0.035419347849264565, -0...   \n",
       "1739  [0.025587070428751937, 0.04954393726535852, 0....   \n",
       "261   [0.1579177659962111, 0.1506932499860362, 0.182...   \n",
       "535   [0.11962444468324915, 0.15292738775326445, 0.1...   \n",
       "\n",
       "                                                      9  ...  \\\n",
       "1860  [0.03889469035733799, 0.009324133203464615, -0...  ...   \n",
       "353   [0.06212325175723368, 0.1338779952545195, 0.06...  ...   \n",
       "1333  [0.16257877243975766, 0.1842083460461648, 0.18...  ...   \n",
       "905   [-0.00013580453213782664, -0.00050997351333200...  ...   \n",
       "1289  [0.14621792762354716, 0.13730709717844508, 0.0...  ...   \n",
       "...                                                 ...  ...   \n",
       "965   [0.10762213290860398, 0.12760665427977877, 0.1...  ...   \n",
       "1284  [-0.009654615671215512, 0.021423906054921428, ...  ...   \n",
       "1739  [0.17405916612586075, 0.10375867622805807, 0.1...  ...   \n",
       "261   [0.011001620037581539, 0.07763397746068441, 0....  ...   \n",
       "535   [0.09664849894042471, 0.08529115282139876, 0.0...  ...   \n",
       "\n",
       "                                                     11  \\\n",
       "1860  [0.02636066665125339, 0.07366375518118445, 0.0...   \n",
       "353   [0.01334744384735444, 0.06200645510184957, 0.0...   \n",
       "1333  [0.10966924095407002, 0.11128181186050445, 0.0...   \n",
       "905   [0.15788749647799102, 0.14578245580334726, 0.1...   \n",
       "1289  [0.1347006492091942, 0.16706253301807883, 0.13...   \n",
       "...                                                 ...   \n",
       "965   [0.029270613900291086, 0.03208893185935524, 0....   \n",
       "1284  [0.007717981046955202, 0.01682810085689792, -0...   \n",
       "1739  [0.10970143396089793, 0.10710204116791225, 0.1...   \n",
       "261   [0.16037842533491392, 0.1413741347070024, 0.14...   \n",
       "535   [0.052767200036594644, 0.0855428795811954, 0.1...   \n",
       "\n",
       "                                                     12  \\\n",
       "1860  [0.05868179674992134, 0.035633105864856573, 0....   \n",
       "353   [-0.01705872551608989, 0.008210816781645345, 0...   \n",
       "1333  [0.10950410175697853, 0.11292570853717471, 0.1...   \n",
       "905   [0.13169664930808866, 0.09399615532051527, 0.1...   \n",
       "1289  [0.1230948622867249, 0.11872826144117227, 0.08...   \n",
       "...                                                 ...   \n",
       "965   [0.13490971592654924, 0.11088642045050949, 0.1...   \n",
       "1284  [0.08422019745863571, 0.013171206723039883, 0....   \n",
       "1739  [0.08858389997945097, 0.1354233513644226, 0.10...   \n",
       "261   [0.05460220213030381, 0.03304292023218894, 0.0...   \n",
       "535   [0.06900184442971712, 0.06003054383298033, 0.0...   \n",
       "\n",
       "                                                     13  \\\n",
       "1860  [0.08014303460720211, 0.029820880448521575, 0....   \n",
       "353   [0.08633689661528213, 0.12400589763125092, 0.1...   \n",
       "1333  [0.07562112819783842, 0.10903873288169735, 0.0...   \n",
       "905   [0.05204856468212047, 0.008372487827550262, 0....   \n",
       "1289  [-0.02624838409533284, -0.02523102455967592, 0...   \n",
       "...                                                 ...   \n",
       "965   [0.027382489936420683, 0.04707731082016241, -0...   \n",
       "1284  [0.050417243291934546, 0.02852431865926448, 0....   \n",
       "1739  [0.12202284305103817, 0.13220191033971584, 0.1...   \n",
       "261   [0.08458951247297508, 0.04247845191685122, 0.0...   \n",
       "535   [0.07095219484039206, 0.045180514372242186, 0....   \n",
       "\n",
       "                                                     14  \\\n",
       "1860  [0.05923256243732212, 0.07010265178662486, 0.0...   \n",
       "353   [0.16467630354705798, 0.11092963165353184, 0.1...   \n",
       "1333  [0.11132856656716986, 0.08505358373684033, 0.0...   \n",
       "905   [0.1407963516870951, 0.10372904960644133, 0.11...   \n",
       "1289  [-0.0029751329999919453, 0.0180230977957846, -...   \n",
       "...                                                 ...   \n",
       "965   [0.10981973821381089, 0.06134068301042721, 0.0...   \n",
       "1284  [0.04273405148331667, -0.024062048521073985, 0...   \n",
       "1739  [0.0977829139163811, 0.10178696275737856, 0.08...   \n",
       "261   [0.07275947630272714, 0.10598496755796272, 0.0...   \n",
       "535   [0.03545570732266198, -0.008890905482849189, -...   \n",
       "\n",
       "                                                     15  \\\n",
       "1860  [0.07720104895997836, 0.0923298173051055, 0.06...   \n",
       "353   [0.017443362970980782, 0.02550759333632542, 0....   \n",
       "1333  [0.04926506668427322, 0.022807663158812132, -0...   \n",
       "905   [0.044560926146349426, -0.02393393043588572, 0...   \n",
       "1289  [0.11257762551525538, 0.11870044723764345, 0.0...   \n",
       "...                                                 ...   \n",
       "965   [0.07022880139832703, 0.10843957005575885, 0.0...   \n",
       "1284  [0.03373844754273273, 0.043420998734551595, -0...   \n",
       "1739  [0.13772268559614928, 0.15322024795091804, 0.1...   \n",
       "261   [0.10002281475099782, 0.10033180198436606, 0.1...   \n",
       "535   [0.03236722536027384, -0.00043939836772954183,...   \n",
       "\n",
       "                                                     16  \\\n",
       "1860  [0.10953594288452118, 0.1474177292428278, 0.12...   \n",
       "353   [0.07455409916885397, 0.07900098684998028, 0.0...   \n",
       "1333  [0.10046067979805748, 0.13282068534696745, 0.1...   \n",
       "905   [0.07495577398365397, 0.13729779060866287, 0.1...   \n",
       "1289  [0.02624932882205603, 0.050241430081379705, 0....   \n",
       "...                                                 ...   \n",
       "965   [0.14970731685539074, 0.12419332074076707, 0.1...   \n",
       "1284  [0.09600130487921885, 0.18144763201027964, 0.1...   \n",
       "1739  [0.0027431957723392, 0.05789473897387325, 0.02...   \n",
       "261   [0.012537603011767512, -0.0019225448207104926,...   \n",
       "535   [0.07183892844738476, 0.05939049776443401, 0.0...   \n",
       "\n",
       "                                                     17  \\\n",
       "1860  [0.04524485153716616, 0.06089447052066114, 0.0...   \n",
       "353   [0.11225897350329125, 0.10373050190273793, 0.1...   \n",
       "1333  [0.11368708991457253, 0.11081266849470546, 0.0...   \n",
       "905   [0.058654183764857835, 0.0694786416642261, 0.0...   \n",
       "1289  [0.095899552759829, 0.06179642215587275, 0.119...   \n",
       "...                                                 ...   \n",
       "965   [0.15025467336008427, 0.1316269461474537, 0.14...   \n",
       "1284  [0.04704052617442797, 0.09225077881264107, 0.0...   \n",
       "1739  [0.009301576010965967, 0.05809421714800441, 0....   \n",
       "261   [0.10820382421948196, 0.062085552036107466, 0....   \n",
       "535   [0.15182938120644857, 0.13661599740524183, 0.1...   \n",
       "\n",
       "                                                     18  \\\n",
       "1860  [0.032481373848488, 0.009201604422756207, 0.02...   \n",
       "353   [0.029629728719411774, -0.013500045378899013, ...   \n",
       "1333  [0.014987804657915937, 0.03270146883940894, -0...   \n",
       "905   [0.14650353958656553, 0.0997859547177187, 0.12...   \n",
       "1289  [0.08109304747905269, 0.07076704353168761, 0.1...   \n",
       "...                                                 ...   \n",
       "965   [0.09530357084016824, 0.07021453226350081, 0.1...   \n",
       "1284  [0.029776917964145236, 0.05304564602257271, 0....   \n",
       "1739  [-0.001911665996093062, -0.029990861168359344,...   \n",
       "261   [0.0891020531206432, 0.0595883297504446, 0.036...   \n",
       "535   [0.09621070734979889, 0.11255830109412886, 0.1...   \n",
       "\n",
       "                                                     19 label  \n",
       "1860  [0.09238452718072016, 0.049265080133587144, 0....     0  \n",
       "353   [0.015176873970044687, 0.060346476349715156, -...     1  \n",
       "1333  [0.157887971021904, 0.17912513335017693, 0.122...     1  \n",
       "905   [0.014424178994388265, 0.08242415753466956, 0....     1  \n",
       "1289  [0.17479168601362755, 0.15031915539486237, 0.1...     1  \n",
       "...                                                 ...   ...  \n",
       "965   [-0.0014050363675178791, 0.032602402850896224,...     1  \n",
       "1284  [0.0487987153769409, -0.0030118234032506866, 0...     0  \n",
       "1739  [0.1602293538247419, 0.09205182017563461, 0.17...     1  \n",
       "261   [0.04325029765388048, 0.03375257683415552, 0.0...     1  \n",
       "535   [0.09001955572949016, 0.07754036079173593, 0.0...     1  \n",
       "\n",
       "[400 rows x 21 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_test\n",
    "test['label'] = y_test\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "61fe6d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "932e9f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.random.randint(10,size=(10,3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "42eae600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "Xt = pca.fit_transform(t)\n",
    "plot = plt.scatter(Xt[:,0], Xt[:,1], c=test[\"label\"])\n",
    "plt.legend(handles=plot.legend_elements()[0], labels=list(test['label']))\n",
    "plt.show()\n",
    "#Zero is sum to 1, 1 is uniform distribution under 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "11fd1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.concatenate(df[features].values.flatten()).reshape(400,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b6729f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.14135194e-02, -1.10443565e-02, -4.21016797e-03, -3.13515518e-02,\n",
       "       -1.34518029e-02,  2.06454131e-02,  1.40375182e-02, -8.04482170e-03,\n",
       "       -9.06029958e-03,  4.87691635e-03, -2.10183028e-02,  1.49124057e-02,\n",
       "       -1.74197893e-02,  2.69913565e-03, -1.11766372e-02,  2.68636385e-02,\n",
       "       -2.75441384e-03, -1.51777372e-02,  3.69269469e-02,  2.49612441e-03,\n",
       "        6.55706933e-02,  3.21778420e-02,  3.41756873e-02,  6.21637653e-02,\n",
       "        3.38427851e-02,  9.39663063e-02,  7.22517728e-02,  3.74122448e-02,\n",
       "        5.88661152e-02,  4.63206698e-02,  6.80638147e-02,  3.19553819e-02,\n",
       "        3.61564842e-02,  3.98144493e-02,  3.39640302e-02,  3.51804938e-02,\n",
       "        4.04451236e-02,  5.79570188e-02,  2.57960230e-02,  6.87679446e-02,\n",
       "        8.43031087e-02,  6.42432440e-02,  1.00638977e-01,  5.29277425e-02,\n",
       "        1.04701834e-01,  5.17068684e-02,  4.66849295e-02,  1.08962782e-01,\n",
       "        6.53014003e-02,  6.59137404e-02,  6.23787381e-02,  4.31637858e-02,\n",
       "        6.90095284e-02,  6.17776755e-02,  6.28554069e-02,  6.67389218e-02,\n",
       "        7.77657120e-02,  6.26468695e-02,  9.68443352e-02,  1.06636286e-01,\n",
       "        5.78486541e-03,  1.49613861e-02,  1.60545478e-02,  6.49183545e-03,\n",
       "        9.01239041e-03,  1.92730131e-03, -2.00253098e-02, -2.09726208e-02,\n",
       "        1.78783949e-02,  3.71918738e-02, -2.12836146e-02,  1.00975873e-02,\n",
       "       -1.37214076e-02, -1.28186669e-02,  1.68029979e-02, -2.40318635e-02,\n",
       "       -2.78095220e-03,  1.08931281e-02,  2.06075597e-02, -7.14266927e-03,\n",
       "        8.29379830e-02,  5.12793124e-02,  4.55120170e-02,  4.71855445e-02,\n",
       "        9.23842829e-02,  4.54962098e-02,  7.44059062e-02,  9.94650645e-02,\n",
       "        5.82140468e-02,  6.81213436e-02,  6.52460868e-02,  8.44776340e-02,\n",
       "        6.74446840e-02,  7.92441896e-02,  1.00931128e-01,  6.63189142e-02,\n",
       "        5.91136108e-02,  9.20971625e-02,  9.42888215e-02,  9.63982318e-02,\n",
       "        1.20716899e-01,  9.36196971e-02,  1.24342675e-01,  1.43432902e-01,\n",
       "        1.34928183e-01,  1.15161129e-01,  8.36873722e-02,  1.10618724e-01,\n",
       "        1.47991197e-01,  1.05110980e-01,  8.11975363e-02,  9.30686337e-02,\n",
       "        8.63553884e-02,  1.15601187e-01,  1.38089916e-01,  1.25769248e-01,\n",
       "        8.83240481e-02,  9.75939936e-02,  1.03402666e-01,  7.85891160e-02,\n",
       "       -5.32149841e-03,  1.07998651e-03,  2.23150456e-02,  8.17414901e-03,\n",
       "        2.64921804e-02, -6.82825588e-03,  1.34487637e-02,  4.69690246e-02,\n",
       "        2.00463186e-02,  2.58192793e-02, -2.25971647e-02,  1.77490543e-03,\n",
       "       -4.28559815e-03, -1.27912505e-03,  4.15396853e-03, -1.39801755e-02,\n",
       "        3.09135699e-02,  4.67558342e-02, -3.96119806e-03,  1.94300735e-02,\n",
       "        1.29538270e-02,  2.50509174e-04,  2.02051851e-02,  2.56611956e-02,\n",
       "        5.59844139e-02,  2.75404590e-02,  5.10555964e-02,  5.14745390e-02,\n",
       "        5.68100767e-03,  6.48143966e-02,  1.62151914e-02,  5.71735150e-02,\n",
       "        3.65185625e-02,  3.39643453e-02,  2.71759359e-02,  3.35674966e-02,\n",
       "       -1.47776090e-03,  1.41022853e-02,  4.82902704e-03,  2.76618776e-02,\n",
       "        2.65994008e-02,  5.59523730e-02,  3.94849666e-02,  6.01326687e-02,\n",
       "        5.80782052e-02,  6.48090523e-02,  5.09315053e-02,  3.94739322e-02,\n",
       "        7.44873604e-02,  6.86260510e-02,  3.21165019e-02,  5.84858083e-02,\n",
       "        4.38228320e-02,  5.48412779e-02,  6.95378696e-02,  2.22114248e-02,\n",
       "        5.83051741e-02,  5.36120141e-02,  6.75938338e-02,  8.17633268e-02,\n",
       "        3.88946904e-02,  9.32413320e-03, -1.69111534e-02,  1.56970771e-02,\n",
       "        1.39732353e-03, -3.59117164e-03, -3.00437395e-03,  1.62878164e-02,\n",
       "       -1.77097378e-02, -2.46997698e-02, -1.41069185e-02, -1.29181661e-02,\n",
       "        3.83224626e-03, -1.16420284e-02,  3.43877842e-03, -1.77573380e-02,\n",
       "        1.12674602e-03,  1.39824519e-02, -1.42170104e-02, -5.06553124e-04,\n",
       "        9.19621928e-03, -1.17001036e-02, -4.00127144e-03,  6.92946662e-04,\n",
       "        3.04784891e-02,  4.50142897e-02,  1.63609035e-02,  7.25529137e-03,\n",
       "       -2.27746683e-02,  4.14777932e-02, -1.92526688e-02,  1.86707717e-03,\n",
       "        1.35823708e-02,  1.11676936e-02,  3.10129073e-02,  4.39789810e-02,\n",
       "        2.57626778e-02,  4.11372076e-03,  3.03048642e-02,  1.61034772e-03,\n",
       "        2.63606667e-02,  7.36637552e-02,  6.48290027e-02,  6.47549479e-02,\n",
       "        2.28626879e-02,  3.18298286e-02,  6.23630887e-02,  7.61864173e-02,\n",
       "        5.83991211e-02,  6.45308447e-02,  6.17711430e-02,  5.15647676e-02,\n",
       "        1.81370484e-02,  5.74098929e-02,  5.17422496e-02,  1.39391283e-02,\n",
       "        3.11034632e-02,  7.38994329e-02,  5.59590262e-02,  5.45657601e-02,\n",
       "        5.86817967e-02,  3.56331059e-02,  4.72958194e-02,  1.07247722e-02,\n",
       "        3.27917599e-02,  4.09089174e-02,  6.24661774e-02,  9.17496699e-03,\n",
       "        2.93602628e-02,  6.66549639e-02,  5.04254413e-02,  8.18947300e-03,\n",
       "        2.84673009e-02,  5.27181586e-02,  5.57600675e-02,  5.35763072e-02,\n",
       "        9.51176982e-03,  1.80452932e-02,  6.80675707e-02,  2.31575712e-02,\n",
       "        8.01430346e-02,  2.98208804e-02,  5.12905190e-02,  4.55111463e-02,\n",
       "        4.48308901e-02,  5.44300873e-02,  6.26945072e-02,  6.74422320e-02,\n",
       "        6.86530971e-02,  6.25347275e-02,  9.03444977e-02,  5.41561538e-02,\n",
       "        6.40767862e-02,  4.05695249e-02,  4.70618671e-02,  6.74746633e-02,\n",
       "        8.88277296e-02,  8.20729208e-02,  4.30319485e-02,  3.71187124e-02,\n",
       "        5.92325624e-02,  7.01026518e-02,  2.85544987e-02,  3.33288547e-02,\n",
       "        9.16601637e-02,  9.24986658e-02,  7.12971133e-02,  4.04824471e-02,\n",
       "        3.71722253e-02,  7.20840817e-02,  2.86780385e-02,  8.29308450e-02,\n",
       "        3.52641106e-02,  8.43690227e-02,  6.40170782e-02,  2.68825905e-02,\n",
       "        4.34134521e-02,  9.23240215e-02,  3.92664434e-02,  9.27038199e-02,\n",
       "        7.72010490e-02,  9.23298173e-02,  6.49145332e-02,  8.72258874e-02,\n",
       "        1.04981086e-01,  8.50942772e-02,  1.34096626e-01,  1.21902030e-01,\n",
       "        8.09066538e-02,  1.23852130e-01,  6.54981660e-02,  6.74632670e-02,\n",
       "        1.11962606e-01,  7.53694926e-02,  9.56688725e-02,  1.33371642e-01,\n",
       "        9.96559526e-02,  1.09720808e-01,  1.26833248e-01,  7.20336406e-02,\n",
       "        1.09535943e-01,  1.47417729e-01,  1.26887404e-01,  1.64396211e-01,\n",
       "        1.09283659e-01,  1.24647590e-01,  1.60402079e-01,  1.59661756e-01,\n",
       "        1.24394350e-01,  1.31531229e-01,  1.40293126e-01,  1.54139082e-01,\n",
       "        1.03107957e-01,  1.59284014e-01,  1.08309508e-01,  1.06472262e-01,\n",
       "        1.28135350e-01,  1.00253114e-01,  1.24854117e-01,  1.55499250e-01,\n",
       "        4.52448515e-02,  6.08944705e-02,  4.26084502e-02,  7.12775287e-02,\n",
       "        9.35380124e-02,  3.90351573e-02,  7.76890127e-02,  3.06773743e-02,\n",
       "        8.27960806e-02,  6.01198483e-02,  7.28155233e-02,  7.52896881e-02,\n",
       "        8.59807148e-02,  6.85041725e-02,  7.93130947e-02,  6.60748316e-02,\n",
       "        9.31769778e-02,  5.77821111e-02,  9.49565309e-02,  2.95991221e-02,\n",
       "        3.24813738e-02,  9.20160442e-03,  2.85128495e-02,  4.80928802e-02,\n",
       "        3.71758949e-02, -1.96703524e-02,  3.44862887e-02, -1.92908130e-02,\n",
       "        2.98123316e-02,  1.44252003e-02, -1.34265280e-04,  3.11295402e-02,\n",
       "        1.21169283e-02, -2.40228490e-02, -5.76331022e-03,  5.52875164e-03,\n",
       "        2.17853516e-02, -1.13213328e-02, -2.13006922e-02, -6.43292623e-03,\n",
       "        9.23845272e-02,  4.92650801e-02,  8.05853198e-02,  8.68279199e-02,\n",
       "        2.76466450e-02,  2.72094989e-02,  3.64828772e-02,  5.90521802e-02,\n",
       "        5.01675243e-02,  4.33447869e-02,  6.62081055e-02,  7.53657898e-02,\n",
       "        4.85420294e-02,  7.01038969e-02,  3.47747272e-02,  9.04054815e-02,\n",
       "        7.33458588e-02,  7.24665139e-02,  7.45570115e-02,  2.43804082e-02])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "eaceff84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09238453, 0.04926508, 0.08058532, 0.08682792, 0.02764665,\n",
       "       0.0272095 , 0.03648288, 0.05905218, 0.05016752, 0.04334479,\n",
       "       0.06620811, 0.07536579, 0.04854203, 0.0701039 , 0.03477473,\n",
       "       0.09040548, 0.07334586, 0.07246651, 0.07455701, 0.02438041])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[19].loc[1860]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ae748a7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35268/395189381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m fig = px.scatter_matrix(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "components = pca.fit_transform(data)\n",
    "labels = {\n",
    "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "}\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    components,\n",
    "    labels=labels,\n",
    "    dimensions=range(4),\n",
    "    color=df[\"species\"]\n",
    ")\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0ac061a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(np.random.randint(10,size=(10,3)))\n",
    "results = PCA(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9782f9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=array([[2, 0, 4],\n",
       "       [9, 6, 9],\n",
       "       [8, 6, 8],\n",
       "       [7, 1, 0],\n",
       "       [6, 6, 7],\n",
       "       [4, 2, 7],\n",
       "       [5, 2, 0],\n",
       "       [2, 4, 2],\n",
       "       [0, 4, 9],\n",
       "       [6, 6, 8]]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf39924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "evaluating\n",
      "Accuracy: 98.0 %\n",
      "0\n",
      "evaluating\n",
      "Accuracy: 98.0 %\n",
      "1\n",
      "evaluating\n",
      "Accuracy: 98.25 %\n",
      "67\n",
      "evaluating\n",
      "Accuracy: 98.0 %\n",
      "128\n",
      "evaluating\n",
      "Accuracy: 98.25 %\n",
      "87\n",
      "evaluating\n",
      "Accuracy: 98.0 %\n",
      "261\n",
      "evaluating\n",
      "Accuracy: 98.25 %\n",
      "510\n",
      "evaluating\n",
      "Accuracy: 98.25 %\n",
      "340\n",
      "evaluating\n",
      "Accuracy: 97.75 %\n",
      "22\n",
      "evaluating\n",
      "Accuracy: 98.0 %\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "from model_utils import MyLoader, set_seed\n",
    "from models import OvO, vaswani, concat\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    test_labels = []\n",
    "    print(\"evaluating\")\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            mod1 = data[0]                    \n",
    "            inp1, labels = mod1\n",
    "            inp1, labels = inp1.to(device), labels.to(device)\n",
    "            inps = []\n",
    "            for i in range(len(data)):\n",
    "                inp, labels = data[i]\n",
    "                inp, labels = inp.to(device), labels.to(device)\n",
    "                inps.append(inp)\n",
    "\n",
    "            inp_len = labels.size(0)\n",
    "            outputs = model(inps) #, model_name\n",
    "            \n",
    "            test_labels.extend(np.array(labels.cpu()))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            pred.extend(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc= 100 * correct / total\n",
    "    print(f'Accuracy: {100 * correct / total} %')\n",
    "    return acc, pred\n",
    "\n",
    "#df = pd.DataFrame(columns = [\"num_modalities\", \"model_name\",  \"test_accuracy\", \"test_list\"]) #,\"FLOPS\" ##pd.read_csv(\"simulation_HP_results.csv\") \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "path_to_data = \"/users/mgolovan/data/mgolovan/simulation_data_vectors/\"\n",
    "X_test = pd.read_pickle(path_to_data + \"X_test.pkl\")\n",
    "y_test = pd.read_pickle(path_to_data + \"y_test.pkl\")\n",
    "\n",
    "#num_modalities = 20\n",
    "model_name = \"OvO\"\n",
    "\n",
    "#,5,10,15,20\n",
    "for i in [20]:\n",
    "    file = glob.glob('/users/mgolovan/data/mgolovan/simulation_data_vectors/models/model_*15*'+ model_name + \"_\"+  str(i) +'_current.pth')[0].split(\"_\")\n",
    "    lr = float(file[3])\n",
    "    bs = int(file[4])\n",
    "    epochs = int(file[6])\n",
    "    heads = int(file[7])\n",
    "    if model_name == \"concat\":\n",
    "        model = concat(i)\n",
    "    elif model_name == \"vaswani\":\n",
    "        model = vaswani(i,heads)\n",
    "    else:\n",
    "        model = OvO(i,heads)\n",
    "    #flops = calc_flops(best_model, i)            \n",
    "    acc = 0\n",
    "    acc_list = []\n",
    "    preds = []\n",
    "    for seed in [15, 0, 1, 67, 128, 87, 261, 510,340, 22]: #15, 0, 1, 67, 128, 87, 261, 510,340, 22\n",
    "        print(seed)\n",
    "        model_path = '/users/mgolovan/data/mgolovan/simulation_data_vectors/models/model_' + str(lr) + \"_\" + str(bs) + \"_\" + str(seed) + \"_\" + str(epochs)+ \"_\" + str(heads) + \"_\" + model_name + \"_\" + str(i)+ '_current.pth'\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu'))) \n",
    "        test_input_list = []\n",
    "\n",
    "        for j in range(i):\n",
    "            test_inputs = torch.load(path_to_data + \"test_modality_\" + str(j) +  \"_inputs.pt\")\n",
    "            test_input_list.append(DataLoader(test_inputs, batch_size=bs, shuffle=False))\n",
    "        test_loader = MyLoader(test_input_list) \n",
    "        \n",
    "        a, pred = eval(model, test_loader) #MISTAKE HERE, should be \"model\" not best_model\n",
    "        acc += a\n",
    "        acc_list.append(a)\n",
    "        preds.append(pred)\n",
    "\n",
    "    df = df.append({'num_modalities': i, \"model_name\": model_name, \"test_accuracy\":acc/10, \"test_list\":acc_list}, ignore_index=True) #\"FLOPS\": flops\n",
    "    #df.to_csv(\"simulation_HP_vaswani_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa623558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_modalities</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>OvO</td>\n",
       "      <td>72.525</td>\n",
       "      <td>[72.0, 72.25, 72.75, 72.75, 72.5, 72.0, 72.25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>OvO</td>\n",
       "      <td>79.800</td>\n",
       "      <td>[80.75, 81.75, 80.0, 78.5, 77.75, 80.25, 80.75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>OvO</td>\n",
       "      <td>87.875</td>\n",
       "      <td>[88.5, 88.0, 87.75, 87.75, 87.25, 88.0, 88.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>OvO</td>\n",
       "      <td>93.225</td>\n",
       "      <td>[92.75, 93.75, 93.25, 93.25, 94.0, 93.75, 93.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>OvO</td>\n",
       "      <td>98.075</td>\n",
       "      <td>[98.0, 98.0, 98.25, 98.0, 98.25, 98.0, 98.25, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_modalities model_name  test_accuracy  \\\n",
       "0              2        OvO         72.525   \n",
       "1              5        OvO         79.800   \n",
       "2             10        OvO         87.875   \n",
       "3             15        OvO         93.225   \n",
       "4             20        OvO         98.075   \n",
       "\n",
       "                                           test_list  \n",
       "0  [72.0, 72.25, 72.75, 72.75, 72.5, 72.0, 72.25,...  \n",
       "1  [80.75, 81.75, 80.0, 78.5, 77.75, 80.25, 80.75...  \n",
       "2  [88.5, 88.0, 87.75, 87.75, 87.25, 88.0, 88.5, ...  \n",
       "3  [92.75, 93.75, 93.25, 93.25, 94.0, 93.75, 93.0...  \n",
       "4  [98.0, 98.0, 98.25, 98.0, 98.25, 98.0, 98.25, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "561c6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"HP_OvO.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10212c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"HP_OvO.csv\").append(pd.read_csv(\"HP_concat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cd171e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = []\n",
    "for i in range(len(df1)):\n",
    "    stds.append(np.array(list(map(float, df1[\"test_list\"].values[i].replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")))).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da6c13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"sd\"] = stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6dd64186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_modalities</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_list</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>OvO</td>\n",
       "      <td>72.525</td>\n",
       "      <td>[72.0, 72.25, 72.75, 72.75, 72.5, 72.0, 72.25,...</td>\n",
       "      <td>0.378319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>OvO</td>\n",
       "      <td>79.800</td>\n",
       "      <td>[80.75, 81.75, 80.0, 78.5, 77.75, 80.25, 80.75...</td>\n",
       "      <td>1.218606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>OvO</td>\n",
       "      <td>87.875</td>\n",
       "      <td>[88.5, 88.0, 87.75, 87.75, 87.25, 88.0, 88.5, ...</td>\n",
       "      <td>0.450694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>OvO</td>\n",
       "      <td>93.225</td>\n",
       "      <td>[92.75, 93.75, 93.25, 93.25, 94.0, 93.75, 93.0...</td>\n",
       "      <td>0.505594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>OvO</td>\n",
       "      <td>98.075</td>\n",
       "      <td>[98.0, 98.0, 98.25, 98.0, 98.25, 98.0, 98.25, ...</td>\n",
       "      <td>0.160078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>concat</td>\n",
       "      <td>72.950</td>\n",
       "      <td>[72.75, 72.75, 73.0, 72.75, 73.0, 73.25, 73.0,...</td>\n",
       "      <td>0.187083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>concat</td>\n",
       "      <td>81.150</td>\n",
       "      <td>[81.5, 81.0, 80.5, 81.25, 81.75, 81.0, 81.25, ...</td>\n",
       "      <td>0.339116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>concat</td>\n",
       "      <td>87.425</td>\n",
       "      <td>[87.75, 88.0, 87.5, 87.5, 87.5, 87.0, 87.25, 8...</td>\n",
       "      <td>0.296859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>concat</td>\n",
       "      <td>92.950</td>\n",
       "      <td>[92.75, 93.0, 93.0, 93.25, 92.75, 93.0, 93.0, ...</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>concat</td>\n",
       "      <td>98.200</td>\n",
       "      <td>[98.25, 98.25, 98.0, 98.25, 98.25, 98.25, 98.2...</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_modalities model_name  test_accuracy  \\\n",
       "0               2        OvO         72.525   \n",
       "1               5        OvO         79.800   \n",
       "2              10        OvO         87.875   \n",
       "3              15        OvO         93.225   \n",
       "4              20        OvO         98.075   \n",
       "0               2     concat         72.950   \n",
       "1               5     concat         81.150   \n",
       "2              10     concat         87.425   \n",
       "3              15     concat         92.950   \n",
       "4              20     concat         98.200   \n",
       "\n",
       "                                           test_list        sd  \n",
       "0  [72.0, 72.25, 72.75, 72.75, 72.5, 72.0, 72.25,...  0.378319  \n",
       "1  [80.75, 81.75, 80.0, 78.5, 77.75, 80.25, 80.75...  1.218606  \n",
       "2  [88.5, 88.0, 87.75, 87.75, 87.25, 88.0, 88.5, ...  0.450694  \n",
       "3  [92.75, 93.75, 93.25, 93.25, 94.0, 93.75, 93.0...  0.505594  \n",
       "4  [98.0, 98.0, 98.25, 98.0, 98.25, 98.0, 98.25, ...  0.160078  \n",
       "0  [72.75, 72.75, 73.0, 72.75, 73.0, 73.25, 73.0,...  0.187083  \n",
       "1  [81.5, 81.0, 80.5, 81.25, 81.75, 81.0, 81.25, ...  0.339116  \n",
       "2  [87.75, 88.0, 87.5, 87.5, 87.5, 87.0, 87.25, 8...  0.296859  \n",
       "3  [92.75, 93.0, 93.0, 93.25, 92.75, 93.0, 93.0, ...  0.150000  \n",
       "4  [98.25, 98.25, 98.0, 98.25, 98.25, 98.25, 98.2...  0.100000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88ca5bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "OvO       AxesSubplot(0.125,0.11;0.775x0.77)\n",
       "concat    AxesSubplot(0.125,0.11;0.775x0.77)\n",
       "Name: test_accuracy, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.groupby(\"model_name\")[\"test_accuracy\"].plot(kind='line',\n",
    "                                                x = \"num_modalities\", y = \"test_accuracy\",\n",
    "                                                yerr = df[\"std\"].values.T, legend=True,capsize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "285bf4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "165d32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"std\"] = stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60c38469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_modalities</th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_list</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>OvO</td>\n",
       "      <td>72.525</td>\n",
       "      <td>[72.0, 72.25, 72.75, 72.75, 72.5, 72.0, 72.25,...</td>\n",
       "      <td>0.378319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>OvO</td>\n",
       "      <td>79.800</td>\n",
       "      <td>[80.75, 81.75, 80.0, 78.5, 77.75, 80.25, 80.75...</td>\n",
       "      <td>1.218606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>OvO</td>\n",
       "      <td>87.875</td>\n",
       "      <td>[88.5, 88.0, 87.75, 87.75, 87.25, 88.0, 88.5, ...</td>\n",
       "      <td>0.450694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>OvO</td>\n",
       "      <td>93.225</td>\n",
       "      <td>[92.75, 93.75, 93.25, 93.25, 94.0, 93.75, 93.0...</td>\n",
       "      <td>0.505594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>OvO</td>\n",
       "      <td>98.075</td>\n",
       "      <td>[98.0, 98.0, 98.25, 98.0, 98.25, 98.0, 98.25, ...</td>\n",
       "      <td>0.160078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_modalities model_name  test_accuracy  \\\n",
       "0              2        OvO         72.525   \n",
       "1              5        OvO         79.800   \n",
       "2             10        OvO         87.875   \n",
       "3             15        OvO         93.225   \n",
       "4             20        OvO         98.075   \n",
       "\n",
       "                                           test_list       std  \n",
       "0  [72.0, 72.25, 72.75, 72.75, 72.5, 72.0, 72.25,...  0.378319  \n",
       "1  [80.75, 81.75, 80.0, 78.5, 77.75, 80.25, 80.75...  1.218606  \n",
       "2  [88.5, 88.0, 87.75, 87.75, 87.25, 88.0, 88.5, ...  0.450694  \n",
       "3  [92.75, 93.75, 93.25, 93.25, 94.0, 93.75, 93.0...  0.505594  \n",
       "4  [98.0, 98.0, 98.25, 98.0, 98.25, 98.0, 98.25, ...  0.160078  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
